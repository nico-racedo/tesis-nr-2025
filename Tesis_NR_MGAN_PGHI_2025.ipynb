{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VnVnmicHolg"
      },
      "source": [
        "![untref.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYzQXh6BPbwD"
      },
      "source": [
        "### Montar Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIDFgN-v_Xjg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except Exception as e:\n",
        "    print(f\"Ocurrió un error al montar Google Drive: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRBhJ5zyPh5w"
      },
      "source": [
        "### Instalación de librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkqicuTKzWAK"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Tensorboard\n",
        "!pip install tensorboard\n",
        "# Métricas objetivas\n",
        "!pip install pesq pystoi --quiet\n",
        "# PGHIPY\n",
        "!pip install pghipy --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cJ-kfXAT9Zv"
      },
      "source": [
        "Debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBDfqgo_YQds"
      },
      "outputs": [],
      "source": [
        "# Debugging\n",
        "%pdb off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FWC6_Z3PpiU"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmQxQNzAw1fH"
      },
      "outputs": [],
      "source": [
        "# Librerías basicas\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "# Audio y procesamiento de señales\n",
        "#import torchaudio\n",
        "#from torchaudio.transforms import Resample #, Spectrogram , GriffinLim\n",
        "from pghipy import stft as stft_pghipy, pghi, istft as istft_pghipy, get_default_window, calculate_synthesis_window\n",
        "import librosa as lib\n",
        "\n",
        "# Métricas objetivas\n",
        "from pesq import pesq, NoUtterancesError\n",
        "from pystoi import stoi\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# IPython para widget de audio\n",
        "import IPython.display as ipd\n",
        "\n",
        "# Progreso\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykI9TPi2dfNh"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orHSPucRdixY"
      },
      "outputs": [],
      "source": [
        "# Directorios\n",
        "BASE_DIR = '/content/drive/MyDrive/TESIS_2025'\n",
        "DATASET_DIR = os.path.join(BASE_DIR, 'Dataset')\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, 'Results', 'R2AttPGHI')\n",
        "TENSORBOARD_DIR = os.path.join(RESULTS_DIR, 'tensorboard')\n",
        "CLEAN_WAV_DIR = os.path.join(DATASET_DIR, 'clean_trainset_28spk_wav')\n",
        "NOISY_WAV_DIR = os.path.join(DATASET_DIR, 'noisy_trainset_28spk_wav')\n",
        "CLEAN_WAV_TESTSET_DIR = os.path.join(DATASET_DIR, 'clean_testset_wav')\n",
        "NOISY_WAV_TESTSET_DIR = os.path.join(DATASET_DIR, 'noisy_testset_wav')\n",
        "CLEAN_STFT_DIR = os.path.join(DATASET_DIR, 'clean_stft_trainset_npz')\n",
        "NOISY_STFT_DIR = os.path.join(DATASET_DIR, 'noisy_stft_trainset_npz')\n",
        "LOG_FILE = os.path.join(DATASET_DIR, 'logfiles', 'log_trainset_28spk.txt')\n",
        "STEP_FILE = os.path.join(RESULTS_DIR, 'save_step.pickle')\n",
        "SUB_TESTSET_FILE = os.path.join(DATASET_DIR, 'test_samples_40.csv')\n",
        "# Define la ruta del CSV en la carpeta RESULTS\n",
        "PESQ_LOG_FILE = os.path.join(RESULTS_DIR, \"pesq_log.csv\")\n",
        "BASIC_TESTS = False\n",
        "\n",
        "# Configuración del dispositivo\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Parámetros del DataLoader\n",
        "BATCH_SIZE = 8\n",
        "N_FFT = 512\n",
        "HOP_LENGTH = N_FFT//8 # 64\n",
        "SR = 16000  # Frecuencia de muestreo (Hz)\n",
        "ORIGINAL_SR = 48000\n",
        "DYNAMIC_RANGE_DB = 120\n",
        "\n",
        "# Parámetros del Generador y Discriminador\n",
        "INPUT_CHANNELS_GEN = 1\n",
        "INPUT_CHANNELS_DISC = 2\n",
        "OUTPUT_CHANNELS = 1\n",
        "NDF = 16\n",
        "LR_GEN = 0.0002\n",
        "LR_DISC = 0.0001\n",
        "MAX_MASK = 1.1\n",
        "\n",
        "# Configuración del entrenamiento\n",
        "EPOCHS = 100\n",
        "# Repeticiones del generador por paso de entrenamiento en el discriminador.\n",
        "GEN_REPEATS = 5\n",
        "# Cada cuantos pasos se monitorea\n",
        "MONITOR_STEP = 100\n",
        "# Cada cuantos pasos se evalua\n",
        "EVALUATION_STEP = 100\n",
        "# Cada cuantos pasos se guarda el modelo\n",
        "SAVE_STEP = 200\n",
        "\n",
        "# Configuración de pérdidas y métricas\n",
        "MAX_PESQ = 4.6\n",
        "L1 = nn.L1Loss()\n",
        "L2 = nn.MSELoss()\n",
        "\n",
        "# Pesos de la pérdida del generador\n",
        "LAMBDA_TF = 0.75       # TIEMPO-FRECUENCIA\n",
        "LAMBDA_METRIC = 0.05  # ADV PESQ\n",
        "LAMBDA_IRM = 0.1     # IRM\n",
        "LAMBDA_TIME = 0.1    # TIEMPO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMHzcOeG3PqF"
      },
      "source": [
        "### Clases\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylfKXOGCpp5C"
      },
      "source": [
        "#### VoiceFileManager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H19Qt9Xy3OGp"
      },
      "outputs": [],
      "source": [
        "class VoiceFileManager:\n",
        "    \"\"\"\n",
        "    Se encarga de manejar las rutas a los archivos de audio\n",
        "    de voz limpia y voz con ruido.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Inicializa las rutas base.\n",
        "        Lee el archivo de logs del dataset.\n",
        "        Lista los archivos de audio.\n",
        "        \"\"\"\n",
        "        self.clean_wav_dir = CLEAN_WAV_DIR\n",
        "        self.noisy_wav_dir = NOISY_WAV_DIR\n",
        "        self.clean_testset_wav_dir = CLEAN_WAV_TESTSET_DIR\n",
        "        self.noisy_testset_wav_dir = NOISY_WAV_TESTSET_DIR\n",
        "        self.clean_npz_dir = CLEAN_STFT_DIR\n",
        "        self.noisy_npz_dir = NOISY_STFT_DIR\n",
        "        self.log = pd.read_csv(LOG_FILE)\n",
        "        self.clean_files = os.listdir(self.clean_wav_dir)\n",
        "        self.noisy_files = os.listdir(self.noisy_wav_dir)\n",
        "        self.clean_testset_files = os.listdir(self.clean_testset_wav_dir)\n",
        "        self.noisy_testset_files = os.listdir(self.noisy_testset_wav_dir)\n",
        "        self._validate_files()\n",
        "        self.current_filename = None\n",
        "\n",
        "    def _validate_files(self) -> None:\n",
        "        \"\"\"\n",
        "        Valida que la cantidad de archivos de audio limpio y ruidoso\n",
        "        coincidan.\n",
        "        \"\"\"\n",
        "        if len(self.clean_files) != len(self.noisy_files):\n",
        "            raise ValueError(\"Clean and noisy files do not match in length.\")\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Retorna la cantidad de archivos de audio.\n",
        "        \"\"\"\n",
        "        return len(self.clean_files)\n",
        "\n",
        "    def get_file_pair(self, idx: int, format: str = '.wav') -> tuple[str, str]:\n",
        "        \"\"\"\n",
        "        Retorna el par de rutas para el audio limpio y ruidoso.\n",
        "\n",
        "        -- Params --\n",
        "        idx: int | indice del archivo.\n",
        "        format: str | formato del archivo.\n",
        "\n",
        "        -- Returns --\n",
        "        clean_path: str | ruta del archivo limpio.\n",
        "        noisy_path: str | ruta del archivo ruidoso.\n",
        "        \"\"\"\n",
        "        # Retorna las rutas correspondientes al archivo limpio\n",
        "        # y ruidoso en el índice idx\n",
        "        clean_file = self.clean_files[idx]\n",
        "        noisy_file = clean_file  # asumiendo que es el mismo nombre\n",
        "        filename = clean_file.split('.')[0]\n",
        "        # Sets current filename\n",
        "        self.current_filename = filename\n",
        "        if format == '.wav':\n",
        "            clean_path = os.path.join(self.clean_wav_dir, clean_file)\n",
        "            noisy_path = os.path.join(self.noisy_wav_dir, noisy_file)\n",
        "        elif format == '.npz':\n",
        "            filename_npz = filename + '.npz'\n",
        "            clean_path = os.path.join(self.clean_npz_dir, filename_npz)\n",
        "            noisy_path = os.path.join(self.noisy_npz_dir, filename_npz)\n",
        "        return clean_path, noisy_path\n",
        "\n",
        "    def get_testset_files(self) -> tuple[list[str], list[str]]:\n",
        "        \"\"\"\n",
        "        Retorna las rutas de los archivos de audio de prueba\n",
        "        limpios y ruidosos.\n",
        "        \"\"\"\n",
        "        clean_file_paths = [\n",
        "            os.path.join(self.clean_testset_wav_dir, filename)\n",
        "            for filename in self.clean_testset_files\n",
        "        ]\n",
        "        noisy_file_paths = [\n",
        "            os.path.join(self.noisy_testset_wav_dir, filename)\n",
        "            for filename in self.clean_testset_files\n",
        "        ]\n",
        "        return clean_file_paths, noisy_file_paths\n",
        "\n",
        "    def get_sub_testset_files(self, extension: str = \".wav\") -> tuple[list[str], list[str]]:\n",
        "        \"\"\"\n",
        "        Retorna las rutas de los archivos de un subconjunto (40)\n",
        "        de los audios de prueba limpios y ruidosos.\n",
        "        \"\"\"\n",
        "        # Leer el CSV\n",
        "        df = pd.read_csv(SUB_TESTSET_FILE)\n",
        "        # Construir la lista de archivos con ruta completa\n",
        "        clean_file_paths = [\n",
        "            os.path.join(self.clean_testset_wav_dir,\n",
        "                         f\"{row['file']}{extension}\") for _, row in df.iterrows()\n",
        "        ]\n",
        "        noisy_file_paths = [\n",
        "            os.path.join(self.noisy_testset_wav_dir,\n",
        "                         f\"{row['file']}{extension}\") for _, row in df.iterrows()\n",
        "        ]\n",
        "        return clean_file_paths, noisy_file_paths\n",
        "\n",
        "    def get_random_test_file(self) -> tuple[str,str,str]:\n",
        "        \"\"\"\n",
        "        Selecciona un par aleatorio de voz limpia y con ruido\n",
        "        del conjunto de test.\n",
        "        Retorna las rutas de los archivos y el nombre del archivo.\n",
        "        \"\"\"\n",
        "        clean_file = random.choice(self.clean_testset_files)\n",
        "        noisy_file = clean_file\n",
        "        clean_path = os.path.join(self.clean_testset_wav_dir, clean_file)\n",
        "        noisy_path = os.path.join(self.noisy_testset_wav_dir, noisy_file)\n",
        "        return clean_path, noisy_path, clean_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UajbeifAc81r"
      },
      "outputs": [],
      "source": [
        "if BASIC_TESTS:\n",
        "    # Instance UT\n",
        "    vfm_ut = VoiceFileManager()\n",
        "    # Run Methods\n",
        "    clean_path_ut, noisy_path_ut = vfm_ut.get_file_pair(1)\n",
        "    testset_files_ut = vfm_ut.get_testset_files()\n",
        "    sub_testset_files_ut = vfm_ut.get_sub_testset_files()\n",
        "    clean_random_path_ut, noisy_random_path_ut, file_ut = vfm_ut.get_random_test_file()\n",
        "    # Basics Tests\n",
        "    assert len(vfm_ut) == 11572\n",
        "    assert len(testset_files_ut[0]) == 824\n",
        "    assert len(sub_testset_files_ut[0]) == 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IeSUBAfpuJ0"
      },
      "source": [
        "#### AudioProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqKIPzAaDgTH"
      },
      "outputs": [],
      "source": [
        "class AudioProcessor:\n",
        "    \"\"\"\n",
        "    Carga y resamplea archivos de audio.\n",
        "    Calcula la STFT usando PGHI.\n",
        "    Adapta la STFT para el entrenamiento.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Inicializa el procesador de audio.\n",
        "        Setea las ventanas para el calculo de la STFT utilizando PGHI.\n",
        "        \"\"\"\n",
        "        self.dynamic_range_db = DYNAMIC_RANGE_DB\n",
        "        # Gaussian windows\n",
        "        self.window, self.gamma = get_default_window(N_FFT)\n",
        "        self.synthesis_window = calculate_synthesis_window(N_FFT, HOP_LENGTH, self.window)\n",
        "        # Sampling rate\n",
        "        self.sr = SR\n",
        "\n",
        "\n",
        "    def load_and_resample(self, audio_path: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Carga un audio y lo remuestrea a SR.\n",
        "\n",
        "        -- Params --\n",
        "        audio_path: str | ruta del archivo de audio.\n",
        "\n",
        "        -- Returns --\n",
        "        resampled_audio: np.ndarray (n_samples,) | audio remuestreado.\n",
        "        \"\"\"\n",
        "        resampled_audio, _ = lib.load(audio_path, sr=self.sr)\n",
        "        return resampled_audio # (n_samples,)\n",
        "\n",
        "    def stft(self, audio_np: np.ndarray, complex: bool = False) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Calcula la STFT utilizando pghipy.\n",
        "\n",
        "        -- Params --\n",
        "        audio_np: np.ndarray (n_samples,) | audio.\n",
        "\n",
        "        -- Returns --\n",
        "        stft_matrix: np.ndarray (f,t) | STFT magnitude.\n",
        "        \"\"\"\n",
        "        if not isinstance(audio_np, np.ndarray):\n",
        "            raise TypeError(\"input must be a numpy array\")\n",
        "        stft_matrix = stft_pghipy(audio_np,win_length=N_FFT,hop_length=HOP_LENGTH,window=self.window)\n",
        "        if complex:\n",
        "            return stft_matrix.T # transpose to (f,t)\n",
        "        return np.abs(stft_matrix).T # transpose to (f,t)\n",
        "\n",
        "    def istft(self, mag_stft_np: np.ndarray, original_len: int = None) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Invierte la STFT utilizando pghipy.\n",
        "\n",
        "        -- Params --\n",
        "        mag_stft_np: np.ndarray (f,t) | STFT magnitude.\n",
        "        original_len: int | longitud del audio original.\n",
        "\n",
        "        -- Returns --\n",
        "        audio: np.ndarray (n_samples,) | audio.\n",
        "        \"\"\"\n",
        "        # Check type\n",
        "        if not isinstance(mag_stft_np, np.ndarray):\n",
        "            raise TypeError(\"input must be a numpy array\")\n",
        "        # Recovers [t,f] for inversion\n",
        "        mag_stft_np = np.abs(mag_stft_np).T\n",
        "        # Checks proper dimensions for inversion\n",
        "        try:\n",
        "            t,f = mag_stft_np.shape\n",
        "        except ValueError:\n",
        "            raise ValueError(f\"Se esperaba un np.ndarray 2D, no {mag_stft_np.shape}\")\n",
        "        if f != (N_FFT//2)+1:\n",
        "            raise ValueError(f\"Se esperaba shape[1]=={(N_FFT//2)+1}, no {mag_stft_np.shape}\")\n",
        "        # Estimate phase using PGHI\n",
        "        phase_stft = pghi(mag_stft_np,win_length=N_FFT,hop_length=HOP_LENGTH,gamma=self.gamma)\n",
        "        # complex stft for inversion\n",
        "        stft_complex = mag_stft_np*np.exp(1.0j*phase_stft)\n",
        "        audio = istft_pghipy(stft_complex, win_length=N_FFT, hop_length=HOP_LENGTH, synthesis_window=self.synthesis_window)\n",
        "        if original_len is not None:\n",
        "            audio = audio[:original_len]\n",
        "        return audio # (n_samples,)\n",
        "\n",
        "    def adapt_stft(self, mag_stft_tensor: torch.Tensor) -> tuple[torch.Tensor, float]:\n",
        "        '''\n",
        "        1 - Divide por el maximo. Rango=[0;1] sin compresion\n",
        "        2 - Limita el valor minimo a 10^(-DR/20)\n",
        "        3 - Convierte y comprime a escala logaritmica. Rango=[-DR;0]\n",
        "        4 - Divide por DR. Rango=[-1;0]\n",
        "        5 - Suma 1. Rango=[0;1]\n",
        "\n",
        "\n",
        "        -- Params --\n",
        "        mag_stft_tensor: torch.Tensor | STFT magnitude.\n",
        "\n",
        "        -- Returns --\n",
        "        adapted_stft: torch.Tensor | STFT magnitude.\n",
        "        max_amp: float | valor maximo de la STFT por el que se normalizo\n",
        "        '''\n",
        "        # Normalize by max\n",
        "        mag_stft_tensor = torch.abs(mag_stft_tensor)\n",
        "        max_amp = float(torch.max(mag_stft_tensor))\n",
        "        mag_stft_tensor = mag_stft_tensor / max_amp\n",
        "        # Clamp min amplitude to 10**(-DR/20)\n",
        "        min_amplitude = 10**(-self.dynamic_range_db/20)\n",
        "        mag_stft_tensor = torch.clamp(mag_stft_tensor, min=min_amplitude) # [1e(-DR/20);1]\n",
        "        # To log scale\n",
        "        mag_stft_tensor = 20*torch.log10(mag_stft_tensor) # [-DR;0]\n",
        "        # To [-1;0]\n",
        "        mag_stft_tensor = mag_stft_tensor/(self.dynamic_range_db)\n",
        "        # To [0;1]\n",
        "        mag_stft_tensor = mag_stft_tensor + 1.0\n",
        "        return mag_stft_tensor, max_amp\n",
        "\n",
        "    def deadapt_stft(self, adapted_stft: torch.Tensor, max_amp:float = 1.0) -> torch.Tensor:\n",
        "        '''\n",
        "        Revierte lo realizado en adapt_stft\n",
        "        Si no se provee max_amp devuelve la stft normalizada [0;1]\n",
        "\n",
        "        -- Params --\n",
        "        adapted_stft: torch.Tensor | adapted STFT magnitude.\n",
        "        max_amp: float | valor maximo de la STFT por el que se normalizo (si se conserva)\n",
        "\n",
        "        -- Returns --\n",
        "        stft_mag: torch.Tensor | STFT magnitude. En rango original o [0;1]\n",
        "        '''\n",
        "        # To [-1;0]\n",
        "        stft_mag = adapted_stft - 1.0\n",
        "        # To [-DR;0]\n",
        "        stft_mag_db = stft_mag * self.dynamic_range_db\n",
        "        # To [1e(-DR/20);1]\n",
        "        stft_mag = torch.pow(10.0, stft_mag_db / 20.0)\n",
        "        # To original max amp\n",
        "        stft_mag = stft_mag * max_amp\n",
        "        return stft_mag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RU0PRKtHDHp"
      },
      "outputs": [],
      "source": [
        "if BASIC_TESTS:\n",
        "    # Instance UT\n",
        "    ap_ut = AudioProcessor()\n",
        "    # Run Methods\n",
        "    # Clean and noisy audios UT\n",
        "    clean_audio_ut = ap_ut.load_and_resample(clean_random_path_ut)\n",
        "    noisy_audio_ut = ap_ut.load_and_resample(noisy_random_path_ut)\n",
        "    # Clean and noisy STFTs\n",
        "    clean_stft_ut = ap_ut.stft(clean_audio_ut)\n",
        "    noisy_stft_ut = ap_ut.stft(noisy_audio_ut)\n",
        "    # ISTFTs audios\n",
        "    clean_i_audio_ut = ap_ut.istft(clean_stft_ut, original_len=len(clean_audio_ut))\n",
        "    noisy_i_audio_ut = ap_ut.istft(noisy_stft_ut, original_len=len(noisy_audio_ut))\n",
        "    # To Tensor\n",
        "    clean_stft_ut_t = torch.from_numpy(clean_stft_ut).float()\n",
        "    noisy_stft_ut_t = torch.from_numpy(noisy_stft_ut).float()\n",
        "    # Adapted STFTs\n",
        "    adapted_clean_stft_ut, max_clean_amp = ap_ut.adapt_stft(clean_stft_ut_t)\n",
        "    adapted_noisy_stft_ut, max_noisy_amp = ap_ut.adapt_stft(noisy_stft_ut_t)\n",
        "    # Deadapted STFTs\n",
        "    deadapted_clean_stft_ut = ap_ut.deadapt_stft(adapted_clean_stft_ut, max_amp=max_clean_amp)\n",
        "    deadapted_noisy_stft_ut = ap_ut.deadapt_stft(adapted_noisy_stft_ut, max_amp=max_noisy_amp)\n",
        "    # Basics Tests\n",
        "    assert isinstance(clean_audio_ut, np.ndarray)\n",
        "    assert clean_stft_ut.shape[0] == (N_FFT//2)+1\n",
        "    assert len(clean_i_audio_ut) == len(clean_audio_ut)\n",
        "    assert adapted_clean_stft_ut.size() == deadapted_clean_stft_ut.size() == clean_stft_ut_t.size()\n",
        "    assert adapted_clean_stft_ut.max() == 1\n",
        "    assert adapted_clean_stft_ut.min() == 0\n",
        "    assert deadapted_clean_stft_ut.max() == clean_stft_ut_t.max()\n",
        "    assert deadapted_clean_stft_ut.min() >= 10**(-DYNAMIC_RANGE_DB/20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBk5RRSUtH8p"
      },
      "source": [
        "#### MetricComputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBVolZT6tOjo"
      },
      "outputs": [],
      "source": [
        "class MetricComputer:\n",
        "    \"\"\"\n",
        "    Calcula métricas de evaluación objetiva.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pesq_mode: str = 'wb',\n",
        "                 stoi_extended: bool = False,\n",
        "                 decimals: int = 3):\n",
        "        \"\"\"\n",
        "        Inicializa el objeto encargado de computar las metricas objetivas.\n",
        "\n",
        "        -- Params --\n",
        "        pesq_mode: str | 'wb' para narrowband o 'nb' para wideband.\n",
        "        stoi_extended: bool | True para usar la versión extendida de stoi.\n",
        "        decimals: int | cantidad de decimales para redondear los resultados.\n",
        "        \"\"\"\n",
        "        self.sr = SR\n",
        "        self.pesq_mode = pesq_mode\n",
        "        self.stoi_extended = stoi_extended\n",
        "        self.decimals = decimals\n",
        "\n",
        "    def check_input(self, input, tipo) -> None:\n",
        "        \"\"\"\n",
        "        Comprueba que el input sea del tipo especificado.\n",
        "        Comprueba que tenga shape: (n_samples,).\n",
        "        Si no lo es levanta un TypeError.\n",
        "        \"\"\"\n",
        "        if not isinstance(input, tipo):\n",
        "            raise TypeError(f\"Input must be a {tipo}\")\n",
        "        if len(input.shape) != 1:\n",
        "            raise ValueError(f\"Input must be a 1D numpy array\")\n",
        "\n",
        "    def compute_pesq(self, clean_audio: np.ndarray, enhanced_audio: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Computa pesq utilizando la librería PESQ.\n",
        "        Ante un NoUtterances error setea pesq en aprox. mitad de escala (2.0).\n",
        "\n",
        "        -- Params --\n",
        "        clean_audio: np.ndarray (n_samples,) | audio limpio.\n",
        "        enhanced_audio: np.ndarray (n_samples,) | audio mejorado.\n",
        "\n",
        "        -- Returns --\n",
        "        pesq_score: float | redondeado a self.decimals\n",
        "        \"\"\"\n",
        "        self.check_input(clean_audio, np.ndarray)\n",
        "        self.check_input(enhanced_audio, np.ndarray)\n",
        "        try:\n",
        "            pesq_score = pesq(self.sr, clean_audio, enhanced_audio, self.pesq_mode)\n",
        "        except NoUtterancesError:\n",
        "            pesq_score = 2.0\n",
        "            # Warning\n",
        "            warnings.warn(f\"No Utterances Error. Setting pesq value to {pesq_score}\")\n",
        "        return np.round(pesq_score, self.decimals)\n",
        "\n",
        "    def compute_stoi(self, clean_audio: np.ndarray, enhanced_audio: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Computa stoi utilizando pystoi.\n",
        "\n",
        "        -- Params --\n",
        "        clean_audio: np.ndarray (n_samples,) | audio limpio.\n",
        "        enhanced_audio: np.ndarray (n_samples,) | audio mejorado.\n",
        "\n",
        "        -- Returns --\n",
        "        stoi_score: float | redondeado a self.decimals\n",
        "        \"\"\"\n",
        "        self.check_input(clean_audio, np.ndarray)\n",
        "        self.check_input(enhanced_audio, np.ndarray)\n",
        "        stoi_score = stoi(clean_audio, enhanced_audio, self.sr, extended=self.stoi_extended)\n",
        "        return np.round(stoi_score, self.decimals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oClBz61qzvii"
      },
      "outputs": [],
      "source": [
        "if BASIC_TESTS:\n",
        "    # Instance UT\n",
        "    mc_ut = MetricComputer()\n",
        "    # Run Methods\n",
        "    pesq_ut = mc_ut.compute_pesq(clean_audio_ut, clean_i_audio_ut)\n",
        "    stoi_ut = mc_ut.compute_stoi(clean_audio_ut, clean_i_audio_ut)\n",
        "    # Basics Tests\n",
        "    assert isinstance(pesq_ut, float)\n",
        "    assert isinstance(stoi_ut, float)\n",
        "    assert pesq_ut >= 4.0\n",
        "    assert stoi_ut >= 0.98"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q6RGXhQCqHa"
      },
      "source": [
        "#### Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4fL-X8CCpcH"
      },
      "outputs": [],
      "source": [
        "class Mask:\n",
        "    \"\"\"\n",
        "    Mascara para aplicar a una STFT ruidosa.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mask_matrix: torch.Tensor, max: float = MAX_MASK):\n",
        "        \"\"\"\n",
        "        Inicializa la mascara.\n",
        "\n",
        "        -- Params --\n",
        "        mask_matrix: torch.Tensor | matriz con valores de la mascara.\n",
        "        max: float | valor maximo de la mascara.\n",
        "        \"\"\"\n",
        "        self.max = max\n",
        "        if mask_matrix.max().item() > self.max:\n",
        "            raise ValueError(f\"Max value of mask must be <= {self.max}. \"\n",
        "                             f\"Found: {mask_matrix.max().item()}\")\n",
        "        elif mask_matrix.min().item() < 0:\n",
        "            raise ValueError(f\"Min value of mask must be >= 0\")\n",
        "        self.mask = mask_matrix\n",
        "\n",
        "    def get_tensor(self) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Retorna la mascara como un tensor.\n",
        "        \"\"\"\n",
        "        return self.mask\n",
        "\n",
        "    @staticmethod\n",
        "    def check_equal_shapes(first: torch.Tensor, second: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Comprueba que las dimensiones de dos tensores sean iguales.\n",
        "        Si no lo son levanta un ValueError.\n",
        "\n",
        "        -- Params --\n",
        "        first: torch.Tensor | primer tensor.\n",
        "        second: torch.Tensor | segundo tensor.\n",
        "        \"\"\"\n",
        "        if first.shape != second.shape:\n",
        "            raise ValueError(\n",
        "                f\"Shapes incompatibles. \"\n",
        "                f\"first tensor: {first.shape}. \"\n",
        "                f\"second tensor: {second.shape}\"\n",
        "            )\n",
        "\n",
        "    def apply(self, noisy_stft: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Aplica la mascara a la magnitud de la STFT ruidosa.\n",
        "        La mascara y la stft deben tener la misma forma.\n",
        "        Devuelve la magnitud de la STFT mejorada.\n",
        "\n",
        "        -- Params --\n",
        "        noisy_stft: torch.Tensor | STFT ruidosa.\n",
        "\n",
        "        -- Returns --\n",
        "        enhanced_stft: torch.Tensor\n",
        "        \"\"\"\n",
        "        self.check_equal_shapes(noisy_stft, self.mask)\n",
        "        enhanced_stft = noisy_stft * self.mask\n",
        "        return enhanced_stft\n",
        "\n",
        "    @classmethod\n",
        "    def ideal_ratio_mask(cls, clean_stft: torch.Tensor, noisy_stft: torch.Tensor,\n",
        "                         alpha: int = 1, beta: int = 1, eps: float = 1e-10):\n",
        "        \"\"\"\n",
        "        Calcula la máscara ideal a partir de la magnitud de la STFT limpia y ruidosa.\n",
        "\n",
        "        -- Params --\n",
        "        clean_stft: torch.Tensor | magnitud STFT limpia.\n",
        "        noisy_stft: torch.Tensor | magnitud STFT ruidosa.\n",
        "\n",
        "        -- Returns --\n",
        "        Mask() | máscara irm.\n",
        "        \"\"\"\n",
        "        cls.check_equal_shapes(clean_stft, noisy_stft)\n",
        "        # IRM - alpha=2, beta=0.5 en general\n",
        "        # IAM - alpha=1, beta=1 (ideal amplitude mask)\n",
        "        abs_clean_stft = torch.abs(clean_stft)\n",
        "        abs_noisy_stft = torch.abs(noisy_stft)\n",
        "        # Estimación de la magnitud del ruido\n",
        "        abs_stft_noise = torch.clamp(abs_noisy_stft - abs_clean_stft, min=0)\n",
        "        # Magnitud elevada a alpha (alpha=2 power) (alpha=1, magnitud)\n",
        "        S = torch.pow(abs_clean_stft, alpha)\n",
        "        N = torch.pow(abs_stft_noise, alpha)\n",
        "        # Cálculo de la máscara ideal\n",
        "        ratio = S / (S + N + eps)\n",
        "        irm = torch.pow(ratio, beta)\n",
        "        return cls(irm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1o0hzAehug6"
      },
      "outputs": [],
      "source": [
        "if BASIC_TESTS:\n",
        "    # Instance UT\n",
        "    irm_mask_ut = Mask.ideal_ratio_mask(clean_stft_ut_t, noisy_stft_ut_t, alpha=2, beta=0.5)\n",
        "    iam_mask_ut = Mask.ideal_ratio_mask(clean_stft_ut_t, noisy_stft_ut_t, alpha=1, beta=1)\n",
        "    random_tensor = torch.rand(noisy_stft_ut_t.shape) * MAX_MASK\n",
        "    random_mask_ut = Mask(random_tensor)\n",
        "    # Run Methods\n",
        "    enhanced_stft_ut = irm_mask_ut.apply(noisy_stft_ut_t)\n",
        "    enhanced_random_stft_ut = random_mask_ut.apply(noisy_stft_ut_t)\n",
        "    Mask.check_equal_shapes(enhanced_stft_ut, noisy_stft_ut_t)\n",
        "    mask_tensor_ut = irm_mask_ut.get_tensor()\n",
        "    # Basics Tests\n",
        "    assert irm_mask_ut.mask.max().item() <= MAX_MASK\n",
        "    assert irm_mask_ut.mask.min().item() >= 0\n",
        "    assert isinstance(mask_tensor_ut, torch.Tensor)\n",
        "    assert irm_mask_ut.mask.max().item() == mask_tensor_ut.max().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Jnrj3CyBGy"
      },
      "source": [
        "#### Plotter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOyafo1azloO"
      },
      "outputs": [],
      "source": [
        "class Plotter:\n",
        "    \"\"\"\n",
        "    Plotea audios, espectrogramas y mascaras.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 figsize: tuple[float, float] = (12, 6),\n",
        "                 rows: int = 1, cols: int = 1,\n",
        "                 title: str = None,\n",
        "                 height_ratios: list[int] = None,\n",
        "                 width_ratios: list[int] = None):\n",
        "        \"\"\"\n",
        "        Inicializa el plotter.\n",
        "\n",
        "        -- Params --\n",
        "        figsize: tuple | tamaño de la figura.\n",
        "        rows: int | numero de filas de la figura.\n",
        "        cols: int | numero de columnas de la figura.\n",
        "        title: str | titulo de la figura.\n",
        "        height_ratios: list | lista de ratios de altura para cada fila.\n",
        "        width_ratios: list | lista de ratios de ancho para cada columna.\n",
        "        \"\"\"\n",
        "        self.sr = SR\n",
        "        self.n_fft = N_FFT\n",
        "        self.hop_length = HOP_LENGTH\n",
        "        self.figsize = figsize\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "        self.title = title\n",
        "        self.height_ratios = height_ratios\n",
        "        self.width_ratios = width_ratios\n",
        "        # Crea una Figure y Axes\n",
        "        self.fig, raw_axes = plt.subplots(self.rows, self.cols,\n",
        "                                          figsize=self.figsize,\n",
        "                                          height_ratios=self.height_ratios,\n",
        "                                          width_ratios=self.width_ratios)\n",
        "        # por si row=col=1 se fuerza un arreglo de shape (rows, cols)\n",
        "        self.axes = np.array(raw_axes).reshape(rows, cols)\n",
        "        # Titulo general\n",
        "        self.fig.suptitle(self.title, fontsize=14)\n",
        "\n",
        "    def plot_waveform(self, audio: np.ndarray, position: tuple[int,int]=(0, 0),\n",
        "                      title=\"Waveform\") -> None:\n",
        "        \"\"\"\n",
        "        Grafica un waveform de audio.\n",
        "        -- Params --\n",
        "        audio: np.ndarray | audio.\n",
        "        position: (fila, columna) | ubicación del Axes en la grilla.\n",
        "        title: str | título del subplot.\n",
        "        \"\"\"\n",
        "        ax = self.axes[position]\n",
        "        ax.clear()\n",
        "        lib.display.waveshow(audio, sr=self.sr, ax=ax)\n",
        "        ax.set_xlim(left=0)\n",
        "        ax.set(title=title, xlabel=\"Time [s.]\", ylabel=\"Amplitud\")\n",
        "\n",
        "    def plot_spectrogram(self, mag_stft: np.ndarray,\n",
        "                         position: tuple[int, int] = (0, 0),\n",
        "                         title: str = \"Spectrogram (dB)\") -> None:\n",
        "        \"\"\"\n",
        "        Grafica un espectrograma de magnitud.\n",
        "        -- Params --\n",
        "        mag_stft: np.ndarray     | magnitud de STFT (shape: [freq_bins, time_frames]).\n",
        "        position: (fila, columna)| ubicación del Axes en la grilla.\n",
        "        title: str               | título del subplot.\n",
        "        \"\"\"\n",
        "        ax = self.axes[position]\n",
        "        ax.clear()\n",
        "        S_db = lib.amplitude_to_db(mag_stft, ref=np.max)\n",
        "        img = lib.display.specshow(\n",
        "            S_db,\n",
        "            sr=self.sr,\n",
        "            hop_length=self.hop_length,\n",
        "            x_axis='time',\n",
        "            y_axis='linear',\n",
        "            ax=ax\n",
        "        )\n",
        "        ax.set_xlim(left=0)\n",
        "        ax.set(title=title, xlabel=\"Time [s.]\", ylabel=\"Hz.\")\n",
        "        cbar = plt.colorbar(img, ax=ax, format=\"%+2.0f dB\", fraction=0.02, pad=0.024)\n",
        "        cbar.ax.tick_params(labelsize=9)\n",
        "\n",
        "    def plot_mask(self,\n",
        "                  mask: np.ndarray,\n",
        "                  position: tuple[int, int] = (0, 0),\n",
        "                  title: str = \"Ideal Ratio Mask\") -> None:\n",
        "        \"\"\"\n",
        "        Grafica una máscara (e.g. Ideal Ratio Mask).\n",
        "        -- Params --\n",
        "        mask: np.ndarray         | máscara (shape: [freq_bins, time_frames], valores en [0,1]).\n",
        "        position: (fila, columna)| ubicación del Axes en la grilla.\n",
        "        title: str               | título del subplot.\n",
        "        \"\"\"\n",
        "        ax = self.axes[position]\n",
        "        ax.clear()\n",
        "        # Mostramos la máscara como imagen en escala de tiempo/frecuencia\n",
        "        img = lib.display.specshow(\n",
        "            mask,\n",
        "            sr=self.sr,\n",
        "            hop_length=self.hop_length,\n",
        "            x_axis='time',\n",
        "            y_axis='linear',\n",
        "            ax=ax,\n",
        "            cmap='magma',\n",
        "            vmin=0.0,\n",
        "            vmax=MAX_MASK,\n",
        "        )\n",
        "        ax.set(title=title, xlabel=\"Time [s.]\", ylabel=\"Hz.\")\n",
        "        # Colorbar pequeña para que no desplace los ejes\n",
        "        cbar = plt.colorbar(img, ax=ax, format=\"%.1f\", fraction=0.02, pad=0.024)\n",
        "        cbar.ax.tick_params(labelsize=9)\n",
        "\n",
        "    def show(self):\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-ph5i9ByQNN"
      },
      "outputs": [],
      "source": [
        "if BASIC_TESTS:\n",
        "    # Instance UT\n",
        "    plotter_ut = Plotter(figsize=(24,12),rows=3, cols=2, title=\"Comparative\", height_ratios=[1,4,4])\n",
        "    # Run Methods\n",
        "    plotter_ut.plot_waveform(clean_audio_ut, position=(0, 0), title=\"Clean\")\n",
        "    plotter_ut.plot_waveform(noisy_audio_ut, position=(0, 1), title=\"Noisy\")\n",
        "    plotter_ut.plot_spectrogram(deadapted_clean_stft_ut.numpy(), position=(1, 0), title=None)\n",
        "    plotter_ut.plot_spectrogram(deadapted_noisy_stft_ut.numpy(), position=(1, 1), title=None)\n",
        "    plotter_ut.plot_mask(irm_mask_ut.mask.numpy(), position=(2, 0), title=\"IRM\")\n",
        "    # Se prueba para evaluar si excluir las primeras y ultimas filas de la mascara en la\n",
        "    # funcion de perdida. Es una buena opcion porque en esos valores la IRM no es buena.\n",
        "    iam_mask_w0 = iam_mask_ut.mask.numpy()\n",
        "    iam_mask_w0[:3, ...] = 0\n",
        "    iam_mask_w0[-10:, ...] = 0\n",
        "    # Plot mask with ceros\n",
        "    plotter_ut.plot_mask(iam_mask_w0, position=(2, 1), title=\"IAM\")\n",
        "    plotter_ut.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DH4MJI-dZbW"
      },
      "source": [
        "#### VoiceDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0G_mEps6dFn"
      },
      "outputs": [],
      "source": [
        "class VoiceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset de audios de voz limpia y con ruido.\n",
        "    VoiceBankCorpus + DEMAND\n",
        "    Se cargan las stft precomputadas en .npz para acelerar el entrenamiento.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Inicializa el dataset.\n",
        "        \"\"\"\n",
        "        self.file_manager = VoiceFileManager()\n",
        "        self.audio_proc = AudioProcessor()\n",
        "        self.device = DEVICE\n",
        "        self.dtype = torch.float32\n",
        "        self.target_shape = N_FFT//2\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Retorna la longitud del dataset.\n",
        "        \"\"\"\n",
        "        return len(self.file_manager)\n",
        "\n",
        "    def load_precomputed_npz(self,\n",
        "                              clean_path_wav: str,\n",
        "                              noisy_path_wav: str) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Carga STFT precomputados en .npz.\n",
        "\n",
        "        -- Params --\n",
        "        clean_path_wav: str | path al wav del audio limpio.\n",
        "        noisy_path_wav: str | path al wav del audio con ruido.\n",
        "\n",
        "        -- Returns --\n",
        "        clean_stft_tensor: torch.Tensor | magnitud STFT limpia adaptada.\n",
        "        noisy_stft_tensor: torch.Tensor | magnitud STFT con ruido adaptada.\n",
        "        \"\"\"\n",
        "        filename_clean = os.path.splitext(os.path.basename(clean_path_wav))[0]\n",
        "        filename_noisy = filename_clean\n",
        "        clean_npz_path = os.path.join(self.file_manager.clean_npz_dir, filename_clean + '.npz')\n",
        "        noisy_npz_path = os.path.join(self.file_manager.noisy_npz_dir, filename_noisy + '.npz')\n",
        "        # 2) cargar stft: np.ndarray\n",
        "        with np.load(clean_npz_path) as cdata:\n",
        "            clean_stft_raw = cdata['arr_0']\n",
        "        with np.load(noisy_npz_path) as ndata:\n",
        "            noisy_stft_raw = ndata['arr_0']\n",
        "        # 3) pasar a tensores\n",
        "        clean_stft_tensor = torch.tensor(clean_stft_raw, dtype=self.dtype)\n",
        "        noisy_stft_tensor = torch.tensor(noisy_stft_raw, dtype=self.dtype)\n",
        "        # 4) aplicar adapt_stft\n",
        "        clean_stft_tensor, max_amp_clean = self.audio_proc.adapt_stft(clean_stft_tensor)\n",
        "        noisy_stft_tensor, max_amp_noisy = self.audio_proc.adapt_stft(noisy_stft_tensor)\n",
        "        return clean_stft_tensor, noisy_stft_tensor\n",
        "\n",
        "    def get_random_fragment(self, clean_stft: torch.Tensor,\n",
        "                            noisy_stft: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Retorna un fragmento aleatorio de la STFT.\n",
        "        Devuelve el shape de entrenamiento (target_shape, target_shape) (256,256).\n",
        "\n",
        "        -- Params --\n",
        "        clean_stft: torch.Tensor | magnitud STFT limpia.\n",
        "        noisy_stft: torch.Tensor | magnitud STFT con ruido.\n",
        "\n",
        "        -- Returns --\n",
        "        clean_stft: torch.Tensor | fragmento aleatorio de magnitud STFT limpia.\n",
        "        noisy_stft: torch.Tensor | fragmento aleatorio de magnitud STFT con ruido.\n",
        "        \"\"\"\n",
        "        time_shape = clean_stft.shape[1]\n",
        "        if time_shape < self.target_shape:\n",
        "            raise ValueError(f\"Time shape must be > {self.target_shape}\")\n",
        "        # Random start\n",
        "        start = random.randint(0, time_shape - self.target_shape)\n",
        "        fin = start + self.target_shape\n",
        "        # Fragment\n",
        "        clean_stft = clean_stft[:self.target_shape, start:fin]\n",
        "        noisy_stft = noisy_stft[:self.target_shape, start:fin]\n",
        "        return clean_stft, noisy_stft\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        \"\"\"\n",
        "        Retorna una muestra de entrenamiento.\n",
        "        Compuesto por un fragmento de voz limpio y su correspondiente fragmento con ruido.\n",
        "\n",
        "        -- Params --\n",
        "        idx: int | indice de la muestra en el dataset.\n",
        "\n",
        "        -- Returns --\n",
        "        sample: dict | muestra de entrenamiento.\n",
        "        \"\"\"\n",
        "        clean_path, noisy_path = self.file_manager.get_file_pair(idx)\n",
        "        # Levantamos STFT ya calculada en .npz\n",
        "        clean_stft, noisy_stft = self.load_precomputed_npz(clean_path, noisy_path)\n",
        "        # Pasaje a [freq, time]. Se guardaron como [t,f]!\n",
        "        clean_stft = clean_stft.T\n",
        "        noisy_stft = noisy_stft.T\n",
        "        # Get random fragment in stft.\n",
        "        clean_stft, noisy_stft = self.get_random_fragment(clean_stft, noisy_stft)\n",
        "        # Enviar a dispositivo\n",
        "        clean_stft = clean_stft.to(self.device)\n",
        "        noisy_stft = noisy_stft.to(self.device)\n",
        "        # Add channel dimension\n",
        "        clean_stft = clean_stft.unsqueeze(0)\n",
        "        noisy_stft = noisy_stft.unsqueeze(0)\n",
        "        # Set Filename\n",
        "        filename = self.file_manager.current_filename\n",
        "        return {'clean_noisy_stft': (clean_stft, noisy_stft),\n",
        "                'filename':filename}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U538OYQYIHNT"
      },
      "outputs": [],
      "source": [
        "if BASIC_TESTS:\n",
        "    # Instance UT\n",
        "    dataset_ut = VoiceDataset()\n",
        "    # Run Methods\n",
        "    sample = dataset_ut[0]\n",
        "    clean_stft_sample0 = sample['clean_noisy_stft'][0]\n",
        "    noisy_stft_sample0 = sample['clean_noisy_stft'][1]\n",
        "    filename_sample0 = sample['filename']\n",
        "    # Basic Tests\n",
        "    assert len(dataset_ut) == 11572\n",
        "    assert clean_stft_sample0.shape[1] == clean_stft_sample0.shape[2] == N_FFT//2\n",
        "    assert noisy_stft_sample0.shape[1] == noisy_stft_sample0.shape[2] == N_FFT//2\n",
        "    assert clean_stft_sample0.shape == torch.Size([1, N_FFT//2, N_FFT//2])\n",
        "    assert noisy_stft_sample0.shape == torch.Size([1, N_FFT//2, N_FFT//2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfHOORA9eLhG"
      },
      "source": [
        "#### Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zXDBpz0WZxB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- Incorporado del discriminador ---\n",
        "class LearnableSigmoid(nn.Module):\n",
        "    def __init__(self, in_features, beta=1):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "        self.slope = nn.Parameter(torch.ones(in_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.beta * torch.sigmoid(self.slope * x)\n",
        "\n",
        "# --- Bloques del Generador ---\n",
        "class Attention_block(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(Attention_block, self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True)),\n",
        "            nn.InstanceNorm2d(F_int, affine=True)\n",
        "        )\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True)),\n",
        "            nn.InstanceNorm2d(F_int, affine=True)\n",
        "        )\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True)),\n",
        "            nn.InstanceNorm2d(1, affine=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.prelu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        return x * psi\n",
        "\n",
        "class Up_conv(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(Up_conv, self).__init__()\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.utils.spectral_norm(nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True)),\n",
        "            nn.InstanceNorm2d(ch_out, affine=True),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "class Recurrent_block(nn.Module):\n",
        "    def __init__(self, ch_out, t=2):\n",
        "        super(Recurrent_block, self).__init__()\n",
        "        self.t = t\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True)),\n",
        "            nn.InstanceNorm2d(ch_out, affine=True),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = self.conv(x)\n",
        "      for i in range(1, self.t):\n",
        "          x1 = self.conv(x + x1)\n",
        "      return x1\n",
        "\n",
        "class RRCNN_block(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out, t=2):\n",
        "        super(RRCNN_block, self).__init__()\n",
        "        self.RCNN = nn.Sequential(\n",
        "            Recurrent_block(ch_out, t=t),\n",
        "            Recurrent_block(ch_out, t=t)\n",
        "        )\n",
        "        self.Conv_1x1 = nn.utils.spectral_norm(nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1, padding=0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Conv_1x1(x)\n",
        "        x1 = self.RCNN(x)\n",
        "        return x + x1\n",
        "\n",
        "class R2AttU_Net(nn.Module):\n",
        "    def __init__(self, img_ch=3, output_ch=1, t=2):\n",
        "        super(R2AttU_Net, self).__init__()\n",
        "\n",
        "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Path de Encoding\n",
        "        self.RRCNN1 = RRCNN_block(ch_in=img_ch, ch_out=64, t=t)\n",
        "        self.RRCNN2 = RRCNN_block(ch_in=64, ch_out=128, t=t)\n",
        "        self.RRCNN3 = RRCNN_block(ch_in=128, ch_out=256, t=t)\n",
        "        self.RRCNN4 = RRCNN_block(ch_in=256, ch_out=512, t=t)\n",
        "        self.RRCNN5 = RRCNN_block(ch_in=512, ch_out=1024, t=t)\n",
        "\n",
        "        # Path de Decoding con concat y bloques de atención\n",
        "        self.Up5 = Up_conv(ch_in=1024, ch_out=512)\n",
        "        self.Att5 = Attention_block(F_g=512, F_l=512, F_int=256)\n",
        "        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512, t=t)\n",
        "\n",
        "        self.Up4 = Up_conv(ch_in=512, ch_out=256)\n",
        "        self.Att4 = Attention_block(F_g=256, F_l=256, F_int=128)\n",
        "        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256, t=t)\n",
        "\n",
        "        self.Up3 = Up_conv(ch_in=256, ch_out=128)\n",
        "        self.Att3 = Attention_block(F_g=128, F_l=128, F_int=64)\n",
        "        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128, t=t)\n",
        "\n",
        "        self.Up2 = Up_conv(ch_in=128, ch_out=64)\n",
        "        self.Att2 = Attention_block(F_g=64, F_l=64, F_int=32)\n",
        "        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64, t=t)\n",
        "\n",
        "        # Capa final: conv 1x1 con spectral normalization y activación learnable\n",
        "        self.Conv_1x1 = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)),\n",
        "            LearnableSigmoid(1, beta=MAX_MASK)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoding\n",
        "        x1 = self.RRCNN1(x)\n",
        "        x2 = self.Maxpool(x1); x2 = self.RRCNN2(x2)\n",
        "        x3 = self.Maxpool(x2); x3 = self.RRCNN3(x3)\n",
        "        x4 = self.Maxpool(x3); x4 = self.RRCNN4(x4)\n",
        "        x5 = self.Maxpool(x4); x5 = self.RRCNN5(x5)\n",
        "\n",
        "        # Decoding y concatenación con atención\n",
        "        d5 = self.Up5(x5)\n",
        "        x4 = self.Att5(g=d5, x=x4)\n",
        "        d5 = torch.cat((x4, d5), dim=1)\n",
        "        d5 = self.Up_RRCNN5(d5)\n",
        "\n",
        "        d4 = self.Up4(d5)\n",
        "        x3 = self.Att4(g=d4, x=x3)\n",
        "        d4 = torch.cat((x3, d4), dim=1)\n",
        "        d4 = self.Up_RRCNN4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        x2 = self.Att3(g=d3, x=x2)\n",
        "        d3 = torch.cat((x2, d3), dim=1)\n",
        "        d3 = self.Up_RRCNN3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        x1 = self.Att2(g=d2, x=x1)\n",
        "        d2 = torch.cat((x1, d2), dim=1)\n",
        "        d2 = self.Up_RRCNN2(d2)\n",
        "\n",
        "        d1 = self.Conv_1x1(d2)\n",
        "        return d1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIUHDbOm_Lry"
      },
      "outputs": [],
      "source": [
        "if BASIC_TESTS:\n",
        "    # Instance UT\n",
        "    gen_ut = R2AttU_Net(img_ch=1, output_ch=1, t=3).to(DEVICE)\n",
        "    loaded_state_ut = torch.load(f'{RESULTS_DIR}/test_gen.pth',\n",
        "                                map_location=torch.device(DEVICE))\n",
        "    gen_ut.load_state_dict(loaded_state_ut[\"gen\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGtcUdrWeN5G"
      },
      "source": [
        "#### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlkAFijafdeo"
      },
      "outputs": [],
      "source": [
        "#cmgan disc - Taken from: https://github.com/ruizhecao96/CMGAN/blob/main/src/models/discriminator.py\n",
        "class LearnableSigmoid(nn.Module):\n",
        "    def __init__(self, in_features, beta=1):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "        self.slope = nn.Parameter(torch.ones(in_features))\n",
        "        self.slope.requiresGrad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.beta * torch.sigmoid(self.slope * x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf, in_channel=INPUT_CHANNELS_DISC):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(in_channel, ndf, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "            ),\n",
        "            nn.InstanceNorm2d(ndf, affine=True),\n",
        "            nn.PReLU(ndf),\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(ndf, ndf * 2, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "            ),\n",
        "            nn.InstanceNorm2d(ndf * 2, affine=True),\n",
        "            nn.PReLU(2 * ndf),\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(ndf * 2, ndf * 4, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "            ),\n",
        "            nn.InstanceNorm2d(ndf * 4, affine=True),\n",
        "            nn.PReLU(4 * ndf),\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(ndf * 4, ndf * 8, (4, 4), (2, 2), (1, 1), bias=False)\n",
        "            ),\n",
        "            nn.InstanceNorm2d(ndf * 8, affine=True),\n",
        "            nn.PReLU(8 * ndf),\n",
        "            nn.AdaptiveMaxPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.utils.spectral_norm(nn.Linear(ndf * 8, ndf * 4)),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.PReLU(4 * ndf),\n",
        "            nn.utils.spectral_norm(nn.Linear(ndf * 4, 1)),\n",
        "            LearnableSigmoid(1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        xy = torch.cat([x, y], dim=1)\n",
        "        return self.layers(xy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopJfE01F7pA"
      },
      "source": [
        "#### GanDenoiser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj_vd_NOHGy-"
      },
      "outputs": [],
      "source": [
        "class GanDenoiser:\n",
        "    \"\"\"\n",
        "    Se encarga de reducir ruido en señales de voz.\n",
        "    Utiliza una red generadora r2attunet para estimar una mascara.\n",
        "    de magnitud en el dominio TF (STFT) a partir de la STFT con ruido.\n",
        "    Invierte la STFT utilizando PGHI.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gen):\n",
        "        \"\"\"\n",
        "        Inicializa el GanDenoiser a partir de un generador de mascaras.\n",
        "        \"\"\"\n",
        "        self.gen = gen\n",
        "        # Asegura que el generador se encuentre en modo eval()\n",
        "        self.gen.eval()\n",
        "        self.processor = AudioProcessor()\n",
        "\n",
        "    def get_mask_tensor(self, noisy_stft: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Devuelve el tensor puro de la mascara.\n",
        "        Recibe N muestras de stft de voz con ruido en forma de batch [N,1,F,T].\n",
        "\n",
        "        -- Params --\n",
        "        noisy_stft: torch.Tensor [N,1,F,T] | N-batch de magnitud STFT con ruido.\n",
        "\n",
        "        -- Returns --\n",
        "        mask: torch.Tensor | mascara estimada [N,1,F,T].\n",
        "        \"\"\"\n",
        "        with torch.inference_mode():\n",
        "            mask = self.gen(noisy_stft)\n",
        "        mask = mask.clone()\n",
        "        return mask\n",
        "\n",
        "    def get_stft_segments(self, noisy_stft: torch.Tensor) -> tuple[torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Recibe una stft ruidosa completa y la divide en segmentos temporales\n",
        "        aptos para la entrada al generador.\n",
        "        Devuelve una tupla de N tensores.\n",
        "\n",
        "        -- Params --\n",
        "        noisy_stft: torch.Tensor | magnitud STFT con ruido adaptada para ingresar al generador.\n",
        "\n",
        "        -- Returns --\n",
        "        tuple[torch.Tensor]: tupla de N tensores de entrada al generador.\n",
        "        \"\"\"\n",
        "        # Shape de entrada al generador\n",
        "        target_shape = N_FFT//2 # 256\n",
        "        # La utlima dimension es la temporal\n",
        "        time_shape = noisy_stft.shape[-1]\n",
        "        # Si la STFT ya es multiplo de target shape, solo\n",
        "        # la divide en partes iguales\n",
        "        if time_shape % target_shape == 0: # es multiplo de target shape\n",
        "            n_parts = (time_shape//target_shape)\n",
        "            # Parte la stft en n partes sobre la ultima dimension (la temporal)\n",
        "            return torch.tensor_split(noisy_stft, n_parts, dim=-1)\n",
        "        else:\n",
        "            # Si no es multiplo la repite circularmente hasta completar\n",
        "            # una dimension temporal multiplo\n",
        "            n_parts = (time_shape//target_shape) + 1\n",
        "            # Dimension temporal necesaria\n",
        "            needed_time_shape = n_parts * target_shape\n",
        "            # Parte que se debe agregar del comienzo al final (repeticion circular)\n",
        "            slice_shape = needed_time_shape - time_shape\n",
        "            repeated_part = noisy_stft[..., :slice_shape]\n",
        "            # Tomar los primeros `slice_shape` valores y los concatena al final\n",
        "            circular_stft = torch.cat([noisy_stft, repeated_part], dim=-1)\n",
        "            return torch.tensor_split(circular_stft, n_parts, dim=-1)\n",
        "\n",
        "    def denoise_stft(self, stft_noisy: np.ndarray) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Recibe una STFT con ruido y devuelve una STFT mejorada.\n",
        "        Utiliza un generador metrico R2AttUnet para estimar una mascara.\n",
        "\n",
        "        -- Params --\n",
        "        stft_noisy: np.ndarray | magnitud STFT con ruido.\n",
        "\n",
        "        -- Returns --\n",
        "        enhanced_stft: torch.Tensor | magnitud STFT enhanced.\n",
        "        \"\"\"\n",
        "        enhanced_stft  = []\n",
        "        enhancer_mask = []\n",
        "        # A tensor\n",
        "        stft_noisy = torch.tensor(stft_noisy, dtype=torch.float32).to(DEVICE)\n",
        "        # Se lleva a shape [1, 1, N_FFT//2, T]\n",
        "        stft_noisy = stft_noisy[None, None, :N_FFT//2, :]\n",
        "        # Se adapta al input del generador\n",
        "        stft_norm, _ = self.processor.adapt_stft(stft_noisy)\n",
        "        # Se obtienen los segmentos. Tupla de tensores con shape [1, 1, N_FFT//2, N_FFT//2]\n",
        "        stft_segments  = self.get_stft_segments(stft_norm)\n",
        "        for input_stft in stft_segments:\n",
        "            mask_tensor = self.get_mask_tensor(input_stft)\n",
        "            mask = Mask(mask_tensor, max=1.2)\n",
        "            enhanced_input = mask.apply(input_stft)\n",
        "            enhanced_stft.append(enhanced_input)\n",
        "            enhancer_mask.append(mask_tensor)\n",
        "        enhanced_stft = torch.cat(enhanced_stft, dim=-1)\n",
        "        enhancer_mask = torch.cat(enhancer_mask, dim=-1)\n",
        "        # Repito la ultima banda de frecuencia [1, 1, N_FFT//2 + 1, T]\n",
        "        enhanced_stft = torch.cat((enhanced_stft, enhanced_stft[:,:,-1:,:]), dim=2)\n",
        "        enhancer_mask = torch.cat((enhancer_mask, enhancer_mask[:,:,-1:,:]), dim=2)\n",
        "        # Se recorta a la longitud temporal de la stft original\n",
        "        enhanced_stft = enhanced_stft[:,:,:,:stft_noisy.shape[-1]]\n",
        "        enhancer_mask = enhancer_mask[:,:,:,:stft_noisy.shape[-1]]\n",
        "        return enhanced_stft, enhancer_mask\n",
        "\n",
        "    def denoise_audio(self, noisy_audio: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Recibe una señal de voz con ruido y devuelve una señal de voz mejorada.\n",
        "        Utiliza un generador metrico R2AttUnet para estimar una mascara.\n",
        "        Invierte la STFT utilizando PGHI.\n",
        "\n",
        "        -- Params --\n",
        "        noisy_audio: np.ndarray | señal de voz con ruido.\n",
        "\n",
        "        -- Returns --\n",
        "        audio_enh: np.ndarray | señal de voz mejorada.\n",
        "        \"\"\"\n",
        "        stft_noisy  = self.processor.stft(noisy_audio) # [F,T]\n",
        "        enhanced_stft, enhancer_mask = self.denoise_stft(stft_noisy) # [1,1,N_FFT//2,T]\n",
        "        # De-adaptar y a numpy\n",
        "        enhanced_stft = self.processor.deadapt_stft(enhanced_stft)\n",
        "        self.enhanced_stft = enhanced_stft.squeeze(0).squeeze(0).cpu().numpy()\n",
        "        self.enhancer_mask = enhancer_mask.squeeze(0).squeeze(0).cpu().numpy()\n",
        "        # Invertir audio\n",
        "        audio_enhanced = self.processor.istft(self.enhanced_stft)\n",
        "        return audio_enhanced[:len(noisy_audio)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcMpt0pYXMiN"
      },
      "outputs": [],
      "source": [
        "if BASIC_TESTS:\n",
        "    # Instance UT\n",
        "    denoiser_ut = GanDenoiser(gen_ut)\n",
        "    # Run methods\n",
        "    enhanced_audio = denoiser_ut.denoise_audio(noisy_audio_ut)\n",
        "    enhanced_stft = denoiser_ut.enhanced_stft\n",
        "    print(enhanced_stft.max(), enhanced_stft.min())\n",
        "    # Plots\n",
        "    plotter_gan = Plotter(figsize=(24,12),rows=2, cols=2, title=\"Comparative\", height_ratios=[1,4])\n",
        "    # Run Methods\n",
        "    plotter_gan.plot_waveform(noisy_audio_ut, position=(0, 0), title=\"Noisy\")\n",
        "    plotter_gan.plot_waveform(enhanced_audio, position=(0, 1), title=\"Enhanced\")\n",
        "    plotter_gan.plot_spectrogram(deadapted_noisy_stft_ut.numpy(), position=(1, 0), title=None)\n",
        "    plotter_gan.plot_spectrogram(enhanced_stft, position=(1, 1), title=None)\n",
        "    plotter_gan.show()\n",
        "    pesq_value_gan = mc_ut.compute_pesq(clean_audio_ut, enhanced_audio)\n",
        "    print(f'PESQ: {pesq_value_gan}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xWEL0bVTk_L"
      },
      "source": [
        "#### Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHhksI3XTn41"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "\n",
        "    \"\"\"\n",
        "    Se encarga de evaluar el desempeño del modelo.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gen):\n",
        "        self.gen = gen\n",
        "        # Asegura que el generador se encuentre en modo eval\n",
        "        self.gen.eval()\n",
        "        assert not self.gen.training\n",
        "        self.gan_denoiser = GanDenoiser(self.gen)\n",
        "        self.file_manager = VoiceFileManager()\n",
        "        self.audio_processor = AudioProcessor()\n",
        "        self.metric_computer = MetricComputer()\n",
        "        self.results = {}\n",
        "\n",
        "    def save_result(self, filename: str, metric: str, value: float):\n",
        "        \"\"\"\n",
        "        Guarda el resultado de una métrica en el diccionario de resultados.\n",
        "\n",
        "        -- Params --\n",
        "        filename: str | nombre del archivo.\n",
        "        metric: str | nombre de la métrica.\n",
        "        value: float | valor de la métrica.\n",
        "        \"\"\"\n",
        "        if value < 0:\n",
        "            raise ValueError(\"El valor de la métrica es negativo.\")\n",
        "        if filename not in self.results:\n",
        "            self.results[filename] = {}\n",
        "        self.results[filename][metric] = value\n",
        "\n",
        "\n",
        "    def new_test(self, reduced=True):\n",
        "        \"\"\"\n",
        "        Realiza un nuevo testeo del desempeño del modelo.\n",
        "        Sobre todo el set de testing (reduced=False)\n",
        "        o el set de testing reducido (reduced=True).\n",
        "\n",
        "        -- Params --\n",
        "        reduced: bool | si se debe usar el set reducido.\n",
        "        \"\"\"\n",
        "        self.reduced = reduced\n",
        "        self.results = {}  # Reiniciar los resultados\n",
        "        # Setea los filenames\n",
        "        if reduced:\n",
        "            clean_files, noisy_files = self.file_manager.get_sub_testset_files()\n",
        "        else:\n",
        "            clean_files, noisy_files = self.file_manager.get_testset_files()\n",
        "        # Ciclo de test\n",
        "        for clean_file, noisy_file in tqdm(zip(clean_files, noisy_files), total=len(clean_files)):\n",
        "            # Load audios\n",
        "            clean_audio = self.audio_processor.load_and_resample(clean_file)\n",
        "            noisy_audio = self.audio_processor.load_and_resample(noisy_file)\n",
        "            # Denoise\n",
        "            enhanced_audio = self.gan_denoiser.denoise_audio(noisy_audio)\n",
        "            # Compute metrics\n",
        "            filename = clean_file[-12:]\n",
        "            pesq_value = self.metric_computer.compute_pesq(clean_audio, enhanced_audio)\n",
        "            stoi_value = self.metric_computer.compute_stoi(clean_audio, enhanced_audio)\n",
        "            # Save Results\n",
        "            self.save_result(filename, 'pesq', pesq_value)\n",
        "            self.save_result(filename, 'stoi', stoi_value)\n",
        "        return self.results\n",
        "\n",
        "    def print_results_summary(self):\n",
        "        \"\"\"\n",
        "        Imprime un resumen de los resultados.\n",
        "        \"\"\"\n",
        "        if self.reduced:\n",
        "            print('Reduced Test Set Results:')\n",
        "        else:\n",
        "            print('Full Test Set Results:')\n",
        "        mean_pesq, median_pesq = self.mean_median_metric('pesq')\n",
        "        mean_stoi, median_stoi = self.mean_median_metric('stoi')\n",
        "        print(f'PESQ -> Mean: {mean_pesq} | Median: {median_pesq}')\n",
        "        print(f'STOI -> Mean: {mean_stoi} | Median: {median_stoi}')\n",
        "\n",
        "    def mean_median_metric(self, metric: str) -> tuple[float, float]:\n",
        "        \"\"\"\n",
        "        Calcula la media y la mediana de una metrica de los resultados.\n",
        "\n",
        "        -- Params --\n",
        "        metric: str | nombre de la metrica.\n",
        "\n",
        "        -- Returns --\n",
        "        mean: float | media de la metrica.\n",
        "        median: float | mediana de la metrica.\n",
        "        \"\"\"\n",
        "        values = [result[metric] for result in self.results.values()]\n",
        "        mean = sum(values) / len(values)\n",
        "        median = sorted(values)[len(values) // 2]\n",
        "        # Redondeo a 3 decimales\n",
        "        mean = round(mean, 3)\n",
        "        median = round(median, 3)\n",
        "        return mean, median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef3AfxAIcIrr"
      },
      "outputs": [],
      "source": [
        "if BASIC_TESTS:\n",
        "    # Instance UT\n",
        "    evaluator_ut = Evaluator(gen_ut)\n",
        "    results_ut = evaluator_ut.new_test(reduced=True)\n",
        "    evaluator_ut.print_results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o1-clSdDFq3"
      },
      "source": [
        "#### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq3WcMlVDH3j"
      },
      "outputs": [],
      "source": [
        "class Utils:\n",
        "    \"\"\"\n",
        "    Se encarga de proveer metodos utilitarios.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def validate_shape(x: torch.Tensor,\n",
        "                      shape: list[int], var_name: str):\n",
        "        \"\"\"\n",
        "        Valida el shape de un tensor.\n",
        "        Si no coincide levanta un ValueError.\n",
        "\n",
        "        -- Params --\n",
        "        x: torch.Tensor | tensor a validar.\n",
        "        shape: list[int] | shape esperado. Ej:[1,256,256]\n",
        "        var_name: str | nombre de la variable.\n",
        "        \"\"\"\n",
        "        if x.shape != torch.Size(shape):\n",
        "            raise ValueError(\n",
        "                f\"[{var_name}] shape inválida: esperado {shape}, \"\n",
        "                f\"pero recibió {tuple(x.shape)}\"\n",
        "            )\n",
        "\n",
        "    @staticmethod\n",
        "    def validate_range(x: torch.Tensor, var_name: str,\n",
        "                       min_val: float = -1.0, max_val: float = 1.0):\n",
        "        \"\"\"\n",
        "        Valida el rango de un tensor entre un min y max value.\n",
        "        Levanta warning si no se cumple.\n",
        "\n",
        "        -- Params --\n",
        "        x: torch.Tensor | tensor a validar.\n",
        "        var_name: str | nombre de la variable.\n",
        "        min_val: float | valor minimo esperado.\n",
        "        max_val: float | valor maximo esperado.\n",
        "        \"\"\"\n",
        "        actual_min = x.min().item()\n",
        "        actual_max = x.max().item()\n",
        "        if actual_min < min_val or actual_max > max_val:\n",
        "            warnings.warn(\n",
        "                f\"[{var_name}] fuera de rango [{min_val}, {max_val}]: \"\n",
        "                f\"min={actual_min:.4f}, max={actual_max:.4f}\"\n",
        "            )\n",
        "\n",
        "    @staticmethod\n",
        "    def validate_amplitude_range(x: torch.Tensor, var_name: str,\n",
        "                                 min_val: float = -1.0, max_val: float = 1.0,\n",
        "                                 coverage_percent: int = 75):\n",
        "        \"\"\"\n",
        "        Valida que se alcance determinada amplitud dentro del rango.\n",
        "        (default = 75%)\n",
        "        Levanta warnings si no se cumple.\n",
        "\n",
        "        -- Params --\n",
        "        x: torch.Tensor | tensor a validar.\n",
        "        var_name: str | nombre de la variable.\n",
        "        min_val: float | valor minimo esperado.\n",
        "        max_val: float | valor maximo esperado.\n",
        "        coverage_percent: int | porcentaje de cobertura del rango esperado.\n",
        "        \"\"\"\n",
        "        actual_min = x.min().item()\n",
        "        actual_max = x.max().item()\n",
        "        actual_range = actual_max - actual_min\n",
        "        expected_range = max_val - min_val\n",
        "        if actual_range < (coverage_percent/100)*expected_range:\n",
        "            warnings.warn(\n",
        "                f\"[{var_name}] no alcanza el rango total esperado (<{coverage_percent}%): \"\n",
        "                f\"actual_min={actual_min:.4f}, actual_max={actual_max:.4f}\"\n",
        "                f\"esperado: {expected_range:.4f}\"\n",
        "                f\"min_val: {min_val}, max_val: {max_val}\"\n",
        "            )\n",
        "\n",
        "    @staticmethod\n",
        "    def from_numpy_to_tensor(x: np.ndarray) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Convierte un numpy array a un tensor.\n",
        "\n",
        "        -- Params --\n",
        "        x: np.ndarray | array a convertir.\n",
        "\n",
        "        -- Returns --\n",
        "        tensor: torch.Tensor | tensor convertido.\n",
        "        \"\"\"\n",
        "        if isinstance(x, np.ndarray):\n",
        "            return torch.tensor(x, dtype=torch.float32).to(DEVICE)\n",
        "        elif isinstance(x, torch.Tensor):\n",
        "            warnings.warn(\"El input ya es un tensor. Se pasa a DEVICE\")\n",
        "            return x.to(DEVICE)\n",
        "        else:\n",
        "            raise ValueError(f\"El input no es un array ni un tensor. type: {type(x)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def from_tensor_to_numpy(x: torch.Tensor) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Convierte un tensor a un numpy array.\n",
        "\n",
        "        -- Params --\n",
        "        x: torch.Tensor | tensor a convertir.\n",
        "\n",
        "        -- Returns --\n",
        "        array: np.ndarray | array convertido.\n",
        "        \"\"\"\n",
        "        if isinstance(x, torch.Tensor):\n",
        "            return x.cpu().detach().numpy()\n",
        "        elif isinstance(x, np.ndarray):\n",
        "            warnings.warn(\"El input ya es un array. No se realiza nada.\")\n",
        "            return x\n",
        "        else:\n",
        "            raise ValueError(f\"El input no es un tensor ni un array. type: {type(x)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKBA-keFV0_0"
      },
      "source": [
        "#### TrainingMonitor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlqs2uASV0Og"
      },
      "outputs": [],
      "source": [
        "class TrainingMonitor:\n",
        "    \"\"\"\n",
        "    Se encarga de monitorizar el entrenamiento.\n",
        "    Plotea lo que se esta generando y recibiendo.\n",
        "    Permite escuchar los audios generados, y los audios del set de entrenamiento.\n",
        "    \"\"\"\n",
        "    def __init__(self, trainer):\n",
        "        self.trainer = trainer\n",
        "        self.monitor_step = MONITOR_STEP\n",
        "        self.gen = trainer.gen\n",
        "        # Asegura que el generador se encuentre en modo eval\n",
        "        self.gen.eval()\n",
        "        assert not self.gen.training\n",
        "        self.gan_denoiser = GanDenoiser(self.gen)\n",
        "        self.file_manager = VoiceFileManager()\n",
        "        self.audio_processor = AudioProcessor()\n",
        "        self.metric_computer = MetricComputer()\n",
        "        self.set_random_test_examples()\n",
        "\n",
        "    def set_random_test_examples(self):\n",
        "        \"\"\"\n",
        "        Establece los audios, stft y mascaras de monitoreo.\n",
        "        \"\"\"\n",
        "        clean_path, noisy_path, self.filename = self.file_manager.get_random_test_file()\n",
        "        # Audios\n",
        "        self.clean_audio = self.audio_processor.load_and_resample(clean_path)\n",
        "        self.noisy_audio = self.audio_processor.load_and_resample(noisy_path)\n",
        "        self.enhanced_audio = self.gan_denoiser.denoise_audio(self.noisy_audio)\n",
        "        # STFTs\n",
        "        self.clean_stft = self.audio_processor.stft(self.clean_audio)\n",
        "        self.noisy_stft = self.audio_processor.stft(self.noisy_audio)\n",
        "        noisy_stft_t = Utils.from_numpy_to_tensor(self.noisy_stft)\n",
        "        clean_stft_t = Utils.from_numpy_to_tensor(self.clean_stft)\n",
        "        self.enhanced_stft = self.gan_denoiser.enhanced_stft\n",
        "        # Masks\n",
        "        self.enhancer_mask = self.gan_denoiser.enhancer_mask\n",
        "        self.reference_mask = Mask.ideal_ratio_mask(clean_stft_t, noisy_stft_t, alpha=1, beta=1)\n",
        "        self.reference_mask = self.reference_mask.get_tensor()\n",
        "        self.reference_mask = Utils.from_tensor_to_numpy(self.reference_mask)\n",
        "\n",
        "    def print_new_step(self, width: int = 150):\n",
        "        \"\"\"\n",
        "        Plotea el encabezado para un nuevo paso de monitoreo.\n",
        "\n",
        "        -- Params --\n",
        "        width: int | ancho del encabezado.\n",
        "        \"\"\"\n",
        "        text = f\" New Monitor Step - Epoch: {self.trainer.current_epoch}, Step: {self.trainer.current_step} \"\n",
        "        # Crea una línea de \"#\"\n",
        "        border = \"#\" * width\n",
        "        # Centra el texto dentro de la línea, rellenando con \"#\"\n",
        "        header = text.center(width, \"#\")\n",
        "        print(border)\n",
        "        print(header)\n",
        "        print(border)\n",
        "\n",
        "    def plot_stft_wave_comparative(self):\n",
        "        \"\"\"\n",
        "        Plotea una comparativa de audios y stfts\n",
        "        \"\"\"\n",
        "        # Plots\n",
        "        plotter = Plotter(figsize=(24,16),rows=4, cols=2,\n",
        "                          title=f\"Comparative {self.filename}\",\n",
        "                          height_ratios=[1,4,1,4])\n",
        "        # Run Methods\n",
        "        plotter.plot_waveform(self.noisy_audio, position=(0, 0), title=\"Noisy Audio\")\n",
        "        plotter.plot_waveform(self.clean_audio, position=(0, 1), title=\"Clean Audio\")\n",
        "        plotter.plot_spectrogram(self.noisy_stft, position=(1, 0), title=None)\n",
        "        plotter.plot_spectrogram(self.clean_stft, position=(1, 1), title=None)\n",
        "        plotter.plot_waveform(self.noisy_audio, position=(2, 0), title=\"Noisy Audio\")\n",
        "        plotter.plot_waveform(self.enhanced_audio, position=(2, 1), title=\"Enhanced Audio\")\n",
        "        plotter.plot_spectrogram(self.noisy_stft, position=(3, 0), title=None)\n",
        "        plotter.plot_spectrogram(self.enhanced_stft, position=(3, 1), title=None)\n",
        "        plotter.show()\n",
        "\n",
        "    def plot_mask_comparative(self):\n",
        "        \"\"\"\n",
        "        Plotea una comparativa de mascaras\n",
        "        \"\"\"\n",
        "        plotter = Plotter(figsize=(24,6),rows=1, cols=2,\n",
        "                          title=f\"Mask Comparative {self.filename}\")\n",
        "        plotter.plot_mask(self.reference_mask, position=(0, 0), title=\"IAM Mask\")\n",
        "        plotter.plot_mask(self.enhancer_mask, position=(0, 1), title=\"Enhanced Mask\")\n",
        "        plotter.show()\n",
        "\n",
        "    def print_metrics(self):\n",
        "        \"\"\"\n",
        "        Imprime los resultados de las metricas para el caso de monitoreo.\n",
        "        \"\"\"\n",
        "        pesq_value_enh = self.metric_computer.compute_pesq(self.clean_audio, self.enhanced_audio)\n",
        "        stoi_value_enh = self.metric_computer.compute_stoi(self.clean_audio, self.enhanced_audio)\n",
        "        pesq_value_noisy = self.metric_computer.compute_pesq(self.clean_audio, self.noisy_audio)\n",
        "        stoi_value_noisy = self.metric_computer.compute_stoi(self.clean_audio, self.noisy_audio)\n",
        "        # Porcentaje de mejora\n",
        "        pesq_dif = round(pesq_value_enh - pesq_value_noisy, 2)\n",
        "        stoi_dif = round(stoi_value_enh - stoi_value_noisy, 2)\n",
        "        mejora_pesq = round(pesq_dif/pesq_value_noisy*100,2)\n",
        "        mejora_stoi = round(stoi_dif/stoi_value_noisy*100,2)\n",
        "        print(f'PESQ: {pesq_value_enh}, Noisy PESQ: {pesq_value_noisy}, Δ = {pesq_dif}, Improvement: {mejora_pesq}%')\n",
        "        print(f'STOI: {stoi_value_enh}, Noisy STOI: {stoi_value_noisy}, Δ = {stoi_dif}, Improvement: {mejora_stoi}%')\n",
        "\n",
        "    def listen_audios(self):\n",
        "        \"\"\"\n",
        "        Permite escuchar los audios monitoreados.\n",
        "        \"\"\"\n",
        "        print('Clean Audio:')\n",
        "        display(ipd.Audio(self.clean_audio, rate=SR))\n",
        "        print('Noisy Audio:')\n",
        "        display(ipd.Audio(self.noisy_audio, rate=SR))\n",
        "        print('Enhanced Audio:')\n",
        "        display(ipd.Audio(self.enhanced_audio, rate=SR))\n",
        "\n",
        "    def print_losses(self):\n",
        "        \"\"\"\n",
        "        Imprime las perdidas del generador y el discriminador\n",
        "        cada monitor steps.\n",
        "        \"\"\"\n",
        "        mean_discriminator_loss = trainer.discriminator_loss_sum/self.monitor_step\n",
        "        mean_generator_loss = trainer.generator_loss_sum/self.monitor_step\n",
        "        print(f\"Generator loss: {mean_generator_loss} | \"\n",
        "              f\"Discriminator loss: {mean_discriminator_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90kbK_hEgF8X"
      },
      "source": [
        "#### LossManager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjZFMMIGgIFz"
      },
      "outputs": [],
      "source": [
        "class LossManager():\n",
        "    \"\"\"\n",
        "    Se encarga de gestionar y calcular las funciones de perdida.\n",
        "    Realiza validaciones modulares.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gen, disc):\n",
        "        \"\"\"\n",
        "        Inicializa el LossManager.\n",
        "        \"\"\"\n",
        "        self.gen = gen\n",
        "        self.disc = disc\n",
        "        self.audio_processor = AudioProcessor()\n",
        "        self.metric_computer = MetricComputer()\n",
        "\n",
        "    def tf_loss(self, clean_batch: torch.Tensor,\n",
        "                fake_batch: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calcula la perdida de tiempo-frecuencia.\n",
        "\n",
        "        -- Params --\n",
        "        clean_batch: torch.Tensor | batch de magnitud STFT limpia.\n",
        "        fake_batch: torch.Tensor | batch de magnitud STFT enhanced.\n",
        "\n",
        "        -- Returns --\n",
        "        tf_loss: torch.Tensor | batch de perdida de tiempo-frecuencia.\n",
        "        \"\"\"\n",
        "        assert clean_batch.shape == fake_batch.shape\n",
        "        # Chequeo de rango y amplitud dentro del rango\n",
        "        Utils.validate_range(clean_batch, 'clean_batch', min_val=0, max_val=1)\n",
        "        Utils.validate_range(fake_batch, 'fake_batch', min_val=0, max_val=1)\n",
        "        Utils.validate_amplitude_range(clean_batch, 'clean_batch', min_val=0, max_val=1)\n",
        "        Utils.validate_amplitude_range(fake_batch, 'fake_batch', min_val=0, max_val=1)\n",
        "        # Time-Frequency Loss\n",
        "        tf_loss = L1(clean_batch, fake_batch)\n",
        "        return tf_loss\n",
        "\n",
        "    def time_loss(self, clean_audio_batch: torch.Tensor,\n",
        "                  fake_audio_batch: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calcula la perdida en tiempo.\n",
        "\n",
        "        -- Params --\n",
        "        clean_audio_batch: torch.Tensor | batch de audio limpio.\n",
        "        fake_audio_batch: torch.Tensor | batch de audio enhanced.\n",
        "\n",
        "        -- Returns --\n",
        "        time_loss: torch.Tensor | batch de perdida en tiempo.\n",
        "        \"\"\"\n",
        "        # Chequeo de longitud\n",
        "        assert len(clean_audio_batch) == len(fake_audio_batch)\n",
        "        # Chequeo de rango y amplitud dentro del rango\n",
        "        Utils.validate_range(clean_audio_batch, 'clean_audio_batch')\n",
        "        Utils.validate_range(fake_audio_batch, 'fake_audio_batch')\n",
        "        Utils.validate_amplitude_range(clean_audio_batch, 'clean_audio_batch')\n",
        "        Utils.validate_amplitude_range(fake_audio_batch, 'fake_audio_batch')\n",
        "        # Time Loss\n",
        "        time_loss = L1(clean_audio_batch, fake_audio_batch)\n",
        "        return time_loss\n",
        "\n",
        "    def irm_loss(self, clean_batch: torch.Tensor, noisy_batch: torch.Tensor,\n",
        "                 gen_mask_batch: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calcula la perdida entre la IRM ideal y la generada por el generador.\n",
        "\n",
        "        -- Params --\n",
        "        clean_batch: torch.Tensor | batch de magnitud STFT limpia.\n",
        "        noisy_batch: torch.Tensor | batch de magnitud STFT con ruido.\n",
        "        gen_mask_batch: torch.Tensor | batch de mascaras generadas por el generador.\n",
        "\n",
        "        -- Returns --\n",
        "        irm_loss: torch.Tensor | batch de perdida entre las IRMs ideales y las generadas por el generador.\n",
        "        \"\"\"\n",
        "        assert clean_batch.shape == noisy_batch.shape == gen_mask_batch.shape\n",
        "        # Se chequea que la mascara generada este explotando el rango\n",
        "        Utils.validate_amplitude_range(gen_mask_batch, 'gen_mask_batch', min_val=0, max_val=MAX_MASK)\n",
        "        # IAM Ideal amplitude Mask: alpha=1, beta=1\n",
        "        ideal_ratio_masks = Mask.ideal_ratio_mask(clean_batch, noisy_batch, alpha=1, beta=1)\n",
        "        ideal_ratio_masks = ideal_ratio_masks.get_tensor()\n",
        "        # Frecuencias excluidas de las mascaras para computar la perdida.\n",
        "        excluded_first_frequencies = 3\n",
        "        excluded_last_frecuencies = 10\n",
        "        # Se setean a 0\n",
        "        ideal_ratio_masks[:,:,:excluded_first_frequencies,:] = 0\n",
        "        ideal_ratio_masks[:,:,-excluded_last_frecuencies:,:] = 0\n",
        "        gen_mask_batch[:,:,:excluded_first_frequencies,:] = 0\n",
        "        gen_mask_batch[:,:,-excluded_last_frecuencies:,:] = 0\n",
        "        # Calculo de la perdida entre iam y las mascaras generadas\n",
        "        irm_loss = L1(ideal_ratio_masks, gen_mask_batch)\n",
        "        return irm_loss\n",
        "\n",
        "    def disc_loss(self, clean_stft_batch: torch.Tensor,\n",
        "                  fake_clean_stft_batch: torch.Tensor,\n",
        "                  fake_scores_batch: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calcula la perdida del discriminador.\n",
        "\n",
        "        -- Params --\n",
        "        clean_stft_batch: torch.Tensor | batch de magnitud STFT limpia. [B,1,F,T]\n",
        "        fake_clean_stft_batch: torch.Tensor | batch de magnitud enhanced (fake)\n",
        "        fake_scores_batch: torch.Tensor | batch de scores de pesq normalizado.\n",
        "\n",
        "        -- Returns --\n",
        "        disc_loss: torch.Tensor | perdida del discriminador.\n",
        "        \"\"\"\n",
        "        # Se calcula la prediccion del discriminador\n",
        "        # clean/clean\n",
        "        disc_clean_loss = self.disc(clean_stft_batch, clean_stft_batch)\n",
        "        one = torch.ones_like(disc_clean_loss)\n",
        "        # fake/clean\n",
        "        disc_fake_loss = self.disc(fake_clean_stft_batch, clean_stft_batch)\n",
        "        # Al recibir la misma muestra limpia el disc debe juzgar con 1 (pesq ideal)\n",
        "        loss_real = L2(disc_clean_loss, one) # D(y,y) - 1\n",
        "        # Al recibir lo generado y el pesq de lo generado, debe aprender a estimarlo\n",
        "        loss_fake = L2(disc_fake_loss, fake_scores_batch) # D(G(x),y) - pesq(G(x))\n",
        "        # La perdida final se compone de loss real + loss_fake\n",
        "        disc_loss = loss_real + loss_fake\n",
        "        # disc loss = (D[y,y] - 1) + (D[G(x),y] - pesq[G(x)]) siendo y=clean, x=noisy\n",
        "        return disc_loss\n",
        "\n",
        "    def disc_to_gen_loss(self, fake_clean_stft_batch: torch.Tensor,\n",
        "                         clean_stft_batch: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calcula la perdida del discriminador para el generador.\n",
        "        El generador intenta que el discriminador puntue sus muestras\n",
        "        con un pesq normalizado igual a 1. (Maximizar pesq)\n",
        "\n",
        "        -- Params --\n",
        "        fake_clean_stft_batch: torch.Tensor | batch de magnitud enhanced (fake)\n",
        "        clean_stft_batch: torch.Tensor | batch de magnitud STFT limpia.\n",
        "\n",
        "        -- Returns --\n",
        "        disc_to_gen_loss: torch.Tensor | distancia contra el pesq ideal (1). Equivalente a MAX_PESQ normalizado.\n",
        "        \"\"\"\n",
        "        assert fake_clean_stft_batch.shape == clean_stft_batch.shape\n",
        "        disc_fake_loss = self.disc(fake_clean_stft_batch, clean_stft_batch)\n",
        "        one = torch.ones_like(disc_fake_loss)\n",
        "        disc_to_gen_loss = L2(disc_fake_loss, one)\n",
        "        return disc_to_gen_loss\n",
        "\n",
        "    def istft_batch(self, stft_batch: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Invierte un batch de stfts.\n",
        "        \"\"\"\n",
        "        audio_batch = []\n",
        "        for stft_sample in stft_batch:\n",
        "            # Se lleva a [f,t]\n",
        "            stft_sample = stft_sample.squeeze(0)\n",
        "            # Se repite la ultima fila de frecuencias\n",
        "            stft_sample = torch.cat([stft_sample, stft_sample[-1:,:]], dim=0)\n",
        "            stft_sample = self.audio_processor.deadapt_stft(stft_sample)\n",
        "            stft_sample = Utils.from_tensor_to_numpy(stft_sample)\n",
        "            audio_sample = self.audio_processor.istft(stft_sample)\n",
        "            # normalize\n",
        "            audio_sample = audio_sample / np.max(np.abs(audio_sample))\n",
        "            audio_sample = Utils.from_numpy_to_tensor(audio_sample)\n",
        "            audio_batch.append(audio_sample)\n",
        "        return torch.stack(audio_batch, dim=0)\n",
        "\n",
        "    def compute_normalized_pesq(self, clean_audio_batch: torch.Tensor,\n",
        "                                fake_audio_batch: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calcula el pesq normalizado de un batch a 0-1.\n",
        "\n",
        "        -- Params --\n",
        "        clean_audio_batch: torch.Tensor | batch de audio limpio.\n",
        "        fake_audio_batch: torch.Tensor | batch de audio enhanced.\n",
        "        \"\"\"\n",
        "        normalized_pesq_scores = []\n",
        "        for clean_audio, fake_audio in zip(clean_audio_batch, fake_audio_batch):\n",
        "            try:\n",
        "                clean_audio = Utils.from_tensor_to_numpy(clean_audio)\n",
        "                fake_audio = Utils.from_tensor_to_numpy(fake_audio)\n",
        "                score = self.metric_computer.compute_pesq(clean_audio, fake_audio)\n",
        "                norm_score = (score - 1) / (MAX_PESQ - 1)\n",
        "                norm_score = np.clip(norm_score, 0, 1)\n",
        "                normalized_pesq_scores.append(norm_score)\n",
        "            except NoUtterancesError:\n",
        "                print(f\"No utterances found\")\n",
        "                # si no hay voz se setea score = 2 (0.27 normalizado)\n",
        "                # para no penalizar el entrenamiento\n",
        "                normalized_pesq_scores.append(0.27)\n",
        "            except Exception as e:\n",
        "                print(f\"Error al calcular PESQ: {e}\")\n",
        "                # si hay un error se asigna 0\n",
        "                normalized_pesq_scores.append(0)\n",
        "        normalized_pesq_scores = np.array(normalized_pesq_scores)\n",
        "        normalized_pesq_scores = Utils.from_numpy_to_tensor(normalized_pesq_scores)\n",
        "        # To shape [4,1]\n",
        "        normalized_pesq_scores = normalized_pesq_scores.unsqueeze(1)\n",
        "        return normalized_pesq_scores\n",
        "\n",
        "\n",
        "    def get_disc_loss(self, clean_stft_batch: torch.Tensor,\n",
        "                      noisy_stft_batch: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Se preparan los elementos para calcular la perdida del discriminador.\n",
        "\n",
        "        -- Params --\n",
        "        clean_stft_batch: torch.Tensor | batch de magnitud STFT limpia. [B,1,F,T]\n",
        "        noisy_stft_batch: torch.Tensor | batch de magnitud STFT con ruido. [B,1,F,T]\n",
        "\n",
        "        -- Returns --\n",
        "        disc_loss: torch.Tensor | perdida del discriminador.\n",
        "        \"\"\"\n",
        "        # Se calculan las mascaras y la stft enhanced (fake_clean_stft)\n",
        "        with torch.no_grad():\n",
        "            mask_batch = self.gen(noisy_stft_batch)\n",
        "            # Applies mask\n",
        "            fake_clean_stft_batch = noisy_stft_batch * mask_batch.detach()\n",
        "        # Se invierten los batch de STFTs\n",
        "        clean_audio_batch = self.istft_batch(clean_stft_batch)\n",
        "        fake_audio_batch = self.istft_batch(fake_clean_stft_batch)\n",
        "        # Se calcula el pesq normalizado a 0-1\n",
        "        fake_scores_batch = self.compute_normalized_pesq(clean_audio_batch, fake_audio_batch)\n",
        "        # Se calcula la perdida del discriminador\n",
        "        disc_loss = self.disc_loss(clean_stft_batch, fake_clean_stft_batch, fake_scores_batch)\n",
        "        return disc_loss\n",
        "\n",
        "    def get_gen_loss(self, clean_stft_batch: torch.Tensor,\n",
        "                     noisy_stft_batch: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calcula la perdida del generador.\n",
        "\n",
        "        -- Params --\n",
        "        clean_stft_batch: torch.Tensor | batch de magnitud STFT limpia. [B,1,F,T]\n",
        "        noisy_stft_batch: torch.Tensor | batch de magnitud STFT con ruido. [B,1,F,T]\n",
        "\n",
        "        -- Returns --\n",
        "        gen_loss: torch.Tensor | perdida del generador.\n",
        "        \"\"\"\n",
        "        # Se generan las mascaras para el batch\n",
        "        mask_batch = self.gen(noisy_stft_batch)\n",
        "        # Se aplica la mascara a la stft ruidosa\n",
        "        fake_clean_stft_batch = noisy_stft_batch * mask_batch\n",
        "        # Se invierten los batch de STFT\n",
        "        clean_audio_batch = self.istft_batch(clean_stft_batch)\n",
        "        fake_audio_batch = self.istft_batch(fake_clean_stft_batch)\n",
        "        # Se calcula la perdida tiempo-frecuencia\n",
        "        tf_loss = L1(clean_stft_batch, fake_clean_stft_batch)\n",
        "        # Se calcula la perdida en tiempo\n",
        "        t_loss = self.time_loss(clean_audio_batch, fake_audio_batch)\n",
        "        # Se calcula la perdida contra la IAM\n",
        "        irm_loss = self.irm_loss(clean_stft_batch, noisy_stft_batch, mask_batch)\n",
        "        # Discriminator Loss (pesq)\n",
        "        disc_pesq_loss = self.disc_to_gen_loss(fake_clean_stft_batch, clean_stft_batch)\n",
        "        # Perdida del generador\n",
        "        gen_loss = LAMBDA_TF * tf_loss + LAMBDA_METRIC * disc_pesq_loss + LAMBDA_IRM * irm_loss + LAMBDA_TIME * t_loss\n",
        "        return gen_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DtAXHCjmV3C"
      },
      "source": [
        "#### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyFcnxFlIJ9x"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Inicializa el Trainer.\n",
        "        \"\"\"\n",
        "        self.models_prefix = 'model_NR_MGAN_PGHI'\n",
        "        self.reset_sum_losses()\n",
        "        # Instancia el SummaryWriter para TensorBoard\n",
        "        run_id = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "        self.log_dir = os.path.join(TENSORBOARD_DIR, 'runs', run_id)\n",
        "        self.writer = SummaryWriter(log_dir=self.log_dir)\n",
        "        # GENERADOR\n",
        "        self.gen = R2AttU_Net(img_ch=1, output_ch=1, t=3).to(DEVICE)\n",
        "        # DISCRIMINADOR\n",
        "        self.disc = Discriminator(NDF).to(DEVICE)\n",
        "        # Optimizadores\n",
        "        self.disc_opt = torch.optim.Adam(self.disc.parameters(), lr=LR_DISC)\n",
        "        self.gen_opt = torch.optim.Adam(self.gen.parameters(), lr=LR_GEN)\n",
        "        # Procesador de audio\n",
        "        self.audio_proc = AudioProcessor()\n",
        "        # Lee el ultimo checkpoint\n",
        "        self.read_checkpoint()\n",
        "        # Carga los modelos\n",
        "        self.load_models()\n",
        "        # Instancia el loss manager\n",
        "        self.loss_manager = LossManager(self.gen, self.disc)\n",
        "        # Inicializa la muestra actual de entrenamiento\n",
        "        self.current_train_sample = None\n",
        "\n",
        "    def reset_sum_losses(self):\n",
        "        \"\"\"\n",
        "        Resetea las sumas acumuladas de la perdida del\n",
        "        generador y del discriminador.\n",
        "        \"\"\"\n",
        "        self.generator_loss_sum = 0\n",
        "        self.discriminator_loss_sum = 0\n",
        "\n",
        "    def save_losses_to_tensorbord(self, generator_loss: float,\n",
        "                                  discriminator_loss: float):\n",
        "        \"\"\"\n",
        "        Guarda las pérdidas en TensorBoard.\n",
        "        \"\"\"\n",
        "        self.writer.add_scalar(\"Loss/Generator\", generator_loss, self.current_step)\n",
        "        self.writer.add_scalar(\"Loss/Discriminator\", discriminator_loss, self.current_step)\n",
        "        self.writer.flush()\n",
        "        self.writer.close()\n",
        "\n",
        "    def save_metric_to_tensorboard(self, metric_name: str, metric_value: float, reduced: bool = True):\n",
        "        \"\"\"\n",
        "        Guarda una métrica en TensorBoard.\n",
        "\n",
        "        -- Params --\n",
        "        metric_name: str | nombre de la métrica.\n",
        "        metric_value: float | valor de la métrica.\n",
        "        reduced: bool | si la métrica es del set reducido.\n",
        "        \"\"\"\n",
        "        if reduced:\n",
        "            writer_string = f\"Metric (reduced)/{metric_name}\"\n",
        "        else:\n",
        "            writer_string = f\"Metric (full)/{metric_name}\"\n",
        "        self.writer.add_scalar(writer_string, metric_value, self.current_step)\n",
        "        self.writer.flush()\n",
        "        self.writer.close()\n",
        "\n",
        "    def set_current_train_sample(self, batch_sample: dict):\n",
        "        \"\"\"\n",
        "        Setea las muestras de entrenamiento para el generador y el discriminador.\n",
        "        Asigna la primer mitad del batch es para el generador\n",
        "        y la segunda mitad para el discriminador. Para minimizar la probabilidad\n",
        "        de que ambos accedan exactamente a la misma muestra.\n",
        "\n",
        "        -- Params --\n",
        "        batch_sample: torch.Tensor | muestra de entrenamiento.\n",
        "        \"\"\"\n",
        "        self.current_train_sample = batch_sample\n",
        "        self.clean_stft_batch, self.noisy_stft_batch = batch_sample['clean_noisy_stft']\n",
        "        # Samples para el generador (se toman la primera mitad del batch)\n",
        "        self.clean_stft_for_gen = self.clean_stft_batch[:BATCH_SIZE//2]\n",
        "        self.noisy_stft_for_gen = self.noisy_stft_batch[:BATCH_SIZE//2]\n",
        "        # Valida los shapes\n",
        "        Utils.validate_shape(self.clean_stft_for_gen,\n",
        "                            [BATCH_SIZE//2, 1, N_FFT//2, N_FFT//2],\n",
        "                            'clean_stft_for_gen')\n",
        "        Utils.validate_shape(self.noisy_stft_for_gen,\n",
        "                            [BATCH_SIZE//2, 1, N_FFT//2, N_FFT//2],\n",
        "                            'noisy_stft_for_gen')\n",
        "        # Samples para el discriminador (segunda mitad del batch)\n",
        "        self.clean_stft_for_disc = self.clean_stft_batch[BATCH_SIZE//2:]\n",
        "        self.noisy_stft_for_disc = self.noisy_stft_batch[BATCH_SIZE//2:]\n",
        "        # Valida los shapes\n",
        "        Utils.validate_shape(self.clean_stft_for_disc,\n",
        "                            [BATCH_SIZE//2, 1, N_FFT//2, N_FFT//2],\n",
        "                            'clean_stft_for_disc')\n",
        "        Utils.validate_shape(self.noisy_stft_for_disc,\n",
        "                            [BATCH_SIZE//2, 1, N_FFT//2, N_FFT//2],\n",
        "                            'noisy_stft_for_disc')\n",
        "\n",
        "    @staticmethod\n",
        "    def weights_init(m):\n",
        "        \"\"\"\n",
        "        Inicializa los pesos de la red.\n",
        "        \"\"\"\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "            torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        \"\"\"\n",
        "        Guarda self.current_epoch y self.current_step en un pickle.\n",
        "        \"\"\"\n",
        "        checkpoint = {\n",
        "            'epoch': self.current_epoch,\n",
        "            'step': self.current_step,\n",
        "            'max_pesq': self.avg_max_pesq_milestone,\n",
        "            'max_pesq_step': self.max_pesq_step\n",
        "        }\n",
        "        with open(STEP_FILE, 'wb') as f:\n",
        "            pickle.dump(checkpoint, f)\n",
        "        print(f\"Checkpoint saved: epoch={self.current_epoch}, step={self.current_step}, max_pesq={self.avg_max_pesq_milestone}, max_pesq_step={self.max_pesq_step}\")\n",
        "\n",
        "    def read_checkpoint(self):\n",
        "        \"\"\"\n",
        "        Lee del pickle la información de la última época y step guardados,\n",
        "        y los asigna a self.current_epoch y self.current_step.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            with open(STEP_FILE, 'rb') as f:\n",
        "                checkpoint = pickle.load(f)\n",
        "            self.current_epoch = checkpoint['epoch']\n",
        "            self.current_step = checkpoint['step']\n",
        "            self.avg_max_pesq_milestone = checkpoint['max_pesq']\n",
        "            self.max_pesq_step = checkpoint['max_pesq_step']\n",
        "            print(f\"Checkpoint loaded: epoch={self.current_epoch}, step={self.current_step}\")\n",
        "        except Exception as e:\n",
        "            print(f\"No checkpoint found or error reading checkpoint: {e}\")\n",
        "            self.current_epoch = 0\n",
        "            self.current_step = 0\n",
        "            self.avg_max_pesq_milestone = 0\n",
        "            self.max_pesq_step = 0\n",
        "\n",
        "    def save_models(self):\n",
        "        \"\"\"\n",
        "        Guarda los modelos y el optimizador en un archivo .pth.\n",
        "        \"\"\"\n",
        "        name_pth = f'{RESULTS_DIR}/{self.models_prefix}_epoch_{self.current_epoch}_step_{self.current_step}.pth'\n",
        "        torch.save({'gen': self.gen.state_dict(),\n",
        "                    'gen_opt': self.gen_opt.state_dict(),\n",
        "                    'disc': self.disc.state_dict(),\n",
        "                    'disc_opt': self.disc_opt.state_dict()}, name_pth)\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"\n",
        "        Carga los modelos y el optimizador desde un archivo .pth.\n",
        "        \"\"\"\n",
        "        if self.current_step > 0:\n",
        "            print(f'Loading model from step: {self.current_step}')\n",
        "            loaded_state = torch.load(f'{RESULTS_DIR}/{self.models_prefix}_epoch_{self.current_epoch}_step_{self.current_step}.pth',\n",
        "                                      map_location=torch.device(DEVICE))\n",
        "            self.gen.load_state_dict(loaded_state[\"gen\"])\n",
        "            self.gen_opt.load_state_dict(loaded_state[\"gen_opt\"])\n",
        "            self.disc.load_state_dict(loaded_state[\"disc\"])\n",
        "            self.disc_opt.load_state_dict(loaded_state[\"disc_opt\"])\n",
        "            self.current_step = self.current_step + 1\n",
        "            print(f'Aligning current step with model saved, current_step: {self.current_step}')\n",
        "        else:\n",
        "            print('Not-pretrained...')\n",
        "            self.current_step = 0\n",
        "            #self.gen = self.gen.apply(self.weights_init)\n",
        "            #self.disc = self.disc.apply(self.weights_init)\n",
        "\n",
        "    def update_generator(self):\n",
        "        \"\"\"\n",
        "        Actualiza el generador.\n",
        "        \"\"\"\n",
        "        self.gen_opt.zero_grad() # Zero out the gradient before backpropagation\n",
        "        gen_loss = self.loss_manager.get_gen_loss(self.clean_stft_for_gen,\n",
        "                                                  self.noisy_stft_for_gen)\n",
        "        gen_loss.backward() # Update gradients\n",
        "        self.gen_opt.step() # Update optimizer\n",
        "        return gen_loss\n",
        "\n",
        "    def update_discriminator(self):\n",
        "        \"\"\"\n",
        "        Actualiza el discriminador.\n",
        "        \"\"\"\n",
        "        self.disc_opt.zero_grad() # Zero out the gradient before backpropagation\n",
        "        disc_loss = self.loss_manager.get_disc_loss(self.clean_stft_for_disc,\n",
        "                                                   self.noisy_stft_for_disc)\n",
        "        disc_loss.backward(retain_graph=True) # Update gradients\n",
        "        self.disc_opt.step() # Update optimizer\n",
        "        return disc_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHmOABT6Nrh_"
      },
      "source": [
        "\n",
        "### MAIN\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAFulBYIhAk3"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "audio_dataset = VoiceDataset()\n",
        "# Dataloader, prepares batchs and shuffle samples\n",
        "dataloader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlnX1kOImXtp"
      },
      "outputs": [],
      "source": [
        "# Instancia de trainer\n",
        "trainer = Trainer()\n",
        "# Epoch loop\n",
        "for epoch in range(trainer.current_epoch, EPOCHS):\n",
        "    # Batch loop\n",
        "    for batch_sample in tqdm(dataloader):\n",
        "        # Aseguramos que el generador está en modo entrenamiento.\n",
        "        trainer.gen.train()\n",
        "        assert trainer.gen.training\n",
        "        # Seteamos el current Batch en el trainer\n",
        "        trainer.set_current_train_sample(batch_sample)\n",
        "        # Update discriminator\n",
        "        disc_loss = trainer.update_discriminator()\n",
        "        # Se entrena al generador, GEN_REPEATS veces antes de volver a entrenar al discriminador.\n",
        "        mean_iteration_gen_loss = 0\n",
        "        for _ in range(GEN_REPEATS):\n",
        "            ### Update generator ###\n",
        "            gen_loss = trainer.update_generator()\n",
        "            mean_iteration_gen_loss += gen_loss.item()\n",
        "        # Perdida promedio del generador en las GEN_REPEATS repeticiones.\n",
        "        mean_iteration_gen_loss = mean_iteration_gen_loss/GEN_REPEATS\n",
        "        # Sums to the discriminator loss sum\n",
        "        trainer.discriminator_loss_sum += disc_loss.item()\n",
        "        # Sums to generator loss sum\n",
        "        trainer.generator_loss_sum += mean_iteration_gen_loss\n",
        "        # Save losses to tensorboard\n",
        "        trainer.save_losses_to_tensorbord(mean_iteration_gen_loss, disc_loss.item())\n",
        "        # ---------- MONITOR STEP ------------------\n",
        "        if trainer.current_step % MONITOR_STEP == 0:\n",
        "            monitor = TrainingMonitor(trainer)\n",
        "            monitor.print_new_step()\n",
        "            # Se monitorean las perdidas\n",
        "            monitor.print_losses()\n",
        "            # Se monitorean las stfts y las mascaras\n",
        "            monitor.plot_stft_wave_comparative()\n",
        "            monitor.plot_mask_comparative()\n",
        "            # Se monitorean los audios y las metricas\n",
        "            monitor.print_metrics()\n",
        "            monitor.listen_audios()\n",
        "            # Se resetea la suma de las perdidas\n",
        "            trainer.reset_sum_losses()\n",
        "        # ---------- EVALUATION STEP ------------------\n",
        "        if trainer.current_step % EVALUATION_STEP == 0 and trainer.current_step > 0:\n",
        "            # Se evalua\n",
        "            evaluator = Evaluator(trainer.gen)\n",
        "            evaluator.new_test(reduced=False)\n",
        "            evaluator.print_results_summary()\n",
        "            mean_pesq, median_pesq = evaluator.mean_median_metric('pesq')\n",
        "            mean_stoi, median_stoi = evaluator.mean_median_metric('stoi')\n",
        "            # Se guardan los resultados en Tensorboard\n",
        "            trainer.save_metric_to_tensorboard('mean_pesq', mean_pesq, reduced=evaluator.reduced)\n",
        "            trainer.save_metric_to_tensorboard('median_pesq', median_pesq, reduced=evaluator.reduced)\n",
        "            trainer.save_metric_to_tensorboard('mean_stoi', mean_stoi, reduced=evaluator.reduced)\n",
        "            trainer.save_metric_to_tensorboard('median_stoi', median_stoi, reduced=evaluator.reduced)\n",
        "            # Si hay un nuevo maximo de pesq, tambien guarda el modelo y checkpoint\n",
        "            if mean_pesq > trainer.avg_max_pesq_milestone:\n",
        "                print(f\"New milestone PESQ! 🎉🎉 {mean_pesq} 🎉🎉\")\n",
        "                trainer.avg_max_pesq_milestone = mean_pesq\n",
        "                trainer.max_pesq_step = trainer.current_step\n",
        "                trainer.save_models()\n",
        "                trainer.save_checkpoint()\n",
        "        # ---------- SAVE STEP -----------------------------------------------\n",
        "        if trainer.current_step % SAVE_STEP == 0 and trainer.current_step > 0:\n",
        "            # Se guarda el modelo y el checkpoint\n",
        "            # En caso de interrupcion se retoma de este punto\n",
        "            trainer.save_models()\n",
        "            trainer.save_checkpoint()\n",
        "        # Actualizamos el step y la epoca\n",
        "        trainer.current_step += 1\n",
        "        trainer.current_epoch = trainer.current_step//len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdGlBl7Q6cAo"
      },
      "source": [
        "### Precompute and save stft\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTs3T1pR6eCO"
      },
      "outputs": [],
      "source": [
        "# audio_proc = AudioProcessor()\n",
        "# # Crear carpetas para STFT\n",
        "# os.makedirs(CLEAN_STFT_DIR, exist_ok=True)\n",
        "# os.makedirs(NOISY_STFT_DIR, exist_ok=True)\n",
        "# clean_files = os.listdir(CLEAN_WAV_DIR)\n",
        "# noisy_files = os.listdir(NOISY_WAV_DIR)\n",
        "\n",
        "# for filename in tqdm(clean_files, desc=\"Precomputando STFT sin adapt\"):\n",
        "#     if filename.endswith(\".wav\"):\n",
        "#         clean_path = os.path.join(CLEAN_WAV_DIR, filename)\n",
        "#         noisy_path = os.path.join(NOISY_WAV_DIR, filename)  # asumiendo mismo nombre\n",
        "#         # 1) Cargar audio y resamplear\n",
        "#         clean_audio = audio_proc.load_and_resample(clean_path)\n",
        "#         noisy_audio = audio_proc.load_and_resample(noisy_path)\n",
        "#         # 3) Calcular STFT\n",
        "#         clean_stft = audio_proc.stft(clean_audio)\n",
        "#         noisy_stft = audio_proc.stft(noisy_audio)\n",
        "#         # 4) Guardar en .npz\n",
        "#         base_filename = filename.replace(\".wav\", \".npz\")\n",
        "#         clean_npz_path = os.path.join(CLEAN_STFT_DIR, base_filename)\n",
        "#         noisy_npz_path = os.path.join(NOISY_STFT_DIR, base_filename)\n",
        "#         # Guardamos .npz\n",
        "#         np.savez_compressed(clean_npz_path, clean_stft)\n",
        "#         np.savez_compressed(noisy_npz_path, noisy_stft)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MYzQXh6BPbwD",
        "pRBhJ5zyPh5w",
        "3FWC6_Z3PpiU",
        "ykI9TPi2dfNh",
        "ylfKXOGCpp5C",
        "jBk5RRSUtH8p",
        "7q6RGXhQCqHa",
        "P3Jnrj3CyBGy",
        "2DH4MJI-dZbW",
        "KfHOORA9eLhG",
        "YGtcUdrWeN5G",
        "RopJfE01F7pA",
        "8xWEL0bVTk_L",
        "2o1-clSdDFq3",
        "wKBA-keFV0_0",
        "90kbK_hEgF8X",
        "5DtAXHCjmV3C",
        "YdGlBl7Q6cAo"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1I1obDHP7Dy7xtuJvFDQ69ATKWbQnVKc1",
      "authorship_tag": "ABX9TyMiozgpLCs2y/IvWEZzhYAT"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}